{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gMXsBQz3uNO",
        "outputId": "1bfc398f-feca-439c-aa9f-873e5b462a98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ddrm'...\n",
            "remote: Enumerating objects: 83, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 83 (delta 28), reused 21 (delta 21), pack-reused 38 (from 1)\u001b[K\n",
            "Receiving objects: 100% (83/83), 3.20 MiB | 27.53 MiB/s, done.\n",
            "Resolving deltas: 100% (29/29), done.\n",
            "/content/ddrm\n"
          ]
        }
      ],
      "source": [
        "# fresh start\n",
        "!rm -rf ddrm\n",
        "!git clone https://github.com/bahjat-kawar/ddrm.git\n",
        "%cd ddrm\n",
        "\n",
        "# use Colab's default PyTorch w/ GPU; just add libs DDRM needs\n",
        "!pip -q install pyyaml tqdm pillow numpy scipy einops matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fresh start\n",
        "!rm -rf ddrm\n",
        "!git clone https://github.com/bahjat-kawar/ddrm.git\n",
        "%cd ddrm\n",
        "\n",
        "# use Colab's default PyTorch w/ GPU; just add libs DDRM needs\n",
        "!pip -q install pyyaml tqdm pillow numpy scipy einops matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTAOqjmu_ARn",
        "outputId": "d8972d0a-aa97-466b-fc9f-baafde0e1da0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# folder where DDRM looks for ImageNet models\n",
        "!mkdir -p exp/logs/imagenet\n",
        "\n",
        "# Download links from OpenAI guided-diffusion README\n",
        "BASE=\"https://openaipublic.blob.core.windows.net/diffusion/jul-2021\"\n",
        "\n",
        "# 256x256 (unconditional, class-conditional, classifier)\n",
        "!wget -nc \"$BASE/256x256_diffusion_uncond.pt\" -P exp/logs/imagenet\n",
        "!wget -nc \"$BASE/256x256_diffusion.pt\"        -P exp/logs/imagenet\n",
        "!wget -nc \"$BASE/256x256_classifier.pt\"       -P exp/logs/imagenet\n",
        "\n",
        "# 512x512 (optional; only if you’ll use 512 configs)\n",
        "!wget -nc \"$BASE/512x512_diffusion.pt\"        -P exp/logs/imagenet\n",
        "!wget -nc \"$BASE/512x512_classifier.pt\"       -P exp/logs/imagenet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSdKiJoM6vlq",
        "outputId": "3dadf8e9-f869-4a17-ae38-020708c896ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-23 14:35:53--  https://openaipublic.blob.core.windows.net/diffusion/jul-2021/256x256_diffusion_uncond.pt\n",
            "Resolving openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)... 20.60.244.1\n",
            "Connecting to openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)|20.60.244.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2211383297 (2.1G) [application/octet-stream]\n",
            "Saving to: ‘exp/logs/imagenet/256x256_diffusion_uncond.pt’\n",
            "\n",
            "256x256_diffusion_u 100%[===================>]   2.06G  2.53MB/s    in 12m 30s \n",
            "\n",
            "2025-09-23 14:48:23 (2.81 MB/s) - ‘exp/logs/imagenet/256x256_diffusion_uncond.pt’ saved [2211383297/2211383297]\n",
            "\n",
            "--2025-09-23 14:48:23--  https://openaipublic.blob.core.windows.net/diffusion/jul-2021/256x256_diffusion.pt\n",
            "Resolving openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)... 20.60.244.1\n",
            "Connecting to openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)|20.60.244.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2215479544 (2.1G) [application/octet-stream]\n",
            "Saving to: ‘exp/logs/imagenet/256x256_diffusion.pt’\n",
            "\n",
            "256x256_diffusion.p 100%[===================>]   2.06G  2.73MB/s    in 12m 32s \n",
            "\n",
            "2025-09-23 15:00:56 (2.81 MB/s) - ‘exp/logs/imagenet/256x256_diffusion.pt’ saved [2215479544/2215479544]\n",
            "\n",
            "--2025-09-23 15:00:56--  https://openaipublic.blob.core.windows.net/diffusion/jul-2021/256x256_classifier.pt\n",
            "Resolving openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)... 20.60.244.1\n",
            "Connecting to openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)|20.60.244.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 216496432 (206M) [application/octet-stream]\n",
            "Saving to: ‘exp/logs/imagenet/256x256_classifier.pt’\n",
            "\n",
            "256x256_classifier. 100%[===================>] 206.47M  3.70MB/s    in 57s     \n",
            "\n",
            "2025-09-23 15:01:54 (3.62 MB/s) - ‘exp/logs/imagenet/256x256_classifier.pt’ saved [216496432/216496432]\n",
            "\n",
            "--2025-09-23 15:01:54--  https://openaipublic.blob.core.windows.net/diffusion/jul-2021/512x512_diffusion.pt\n",
            "Resolving openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)... 20.60.244.1\n",
            "Connecting to openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)|20.60.244.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2236135873 (2.1G) [application/octet-stream]\n",
            "Saving to: ‘exp/logs/imagenet/512x512_diffusion.pt’\n",
            "\n",
            "512x512_diffusion.p 100%[===================>]   2.08G  4.06MB/s    in 9m 18s  \n",
            "\n",
            "2025-09-23 15:11:14 (3.82 MB/s) - ‘exp/logs/imagenet/512x512_diffusion.pt’ saved [2236135873/2236135873]\n",
            "\n",
            "--2025-09-23 15:11:14--  https://openaipublic.blob.core.windows.net/diffusion/jul-2021/512x512_classifier.pt\n",
            "Resolving openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)... 20.60.244.1\n",
            "Connecting to openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)|20.60.244.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 217919056 (208M) [application/octet-stream]\n",
            "Saving to: ‘exp/logs/imagenet/512x512_classifier.pt’\n",
            "\n",
            "512x512_classifier. 100%[===================>] 207.82M  3.03MB/s    in 71s     \n",
            "\n",
            "2025-09-23 15:12:26 (2.92 MB/s) - ‘exp/logs/imagenet/512x512_classifier.pt’ saved [217919056/217919056]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ddrm\n",
        "!mkdir -p exp/datasets\n",
        "!rm -rf ddrm-exp-datasets\n",
        "!git clone https://github.com/jiamings/ddrm-exp-datasets.git\n",
        "!cp -r ddrm-exp-datasets/* exp/datasets/\n",
        "!find exp/datasets -maxdepth 2 -type d -print\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7faPpc5Dk7k",
        "outputId": "10652b24-273a-4ef2-9057-ebf1578d8650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ddrm\n",
            "Cloning into 'ddrm-exp-datasets'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 59 (delta 1), reused 53 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (59/59), 3.81 MiB | 47.57 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "exp/datasets\n",
            "exp/datasets/ood\n",
            "exp/datasets/ood/0\n",
            "exp/datasets/ood_bedroom\n",
            "exp/datasets/ood_bedroom/0\n",
            "exp/datasets/ood_celeba\n",
            "exp/datasets/ood_celeba/0\n",
            "exp/datasets/ood_church_outdoor\n",
            "exp/datasets/ood_church_outdoor/0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd /content/ddrm\n",
        "wget -O exp/imagenet_val_1k.txt \\\n",
        "  https://raw.githubusercontent.com/XingangPan/deep-generative-prior/master/scripts/imagenet_val_1k.txt\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnE22i3YFqTX",
        "outputId": "0fafe071-ac2e-4576-ffa0-0ae017c6f119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "--2025-09-23 15:12:45--  https://raw.githubusercontent.com/XingangPan/deep-generative-prior/master/scripts/imagenet_val_1k.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 32890 (32K) [text/plain]\n",
            "Saving to: ‘exp/imagenet_val_1k.txt’\n",
            "\n",
            "     0K .......... .......... .......... ..                   100% 48.4M=0.001s\n",
            "\n",
            "2025-09-23 15:12:45 (48.4 MB/s) - ‘exp/imagenet_val_1k.txt’ saved [32890/32890]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -e\n",
        "cd /content/ddrm\n",
        "\n",
        "# Re-sync the demo datasets into exp/datasets/\n",
        "rm -rf ddrm-exp-datasets\n",
        "git clone --depth 1 https://github.com/jiamings/ddrm-exp-datasets.git\n",
        "mkdir -p exp/datasets\n",
        "rsync -a ddrm-exp-datasets/ exp/datasets/\n",
        "\n",
        "# Show how many image files we have (recursive) and print a few\n",
        "echo \"Counting images under exp/datasets (recursive)…\"\n",
        "find exp/datasets -type f -iregex '.*\\.\\(jpg\\|jpeg\\|png\\)$' | wc -l\n",
        "echo \"--- samples ---\"\n",
        "find exp/datasets -type f -iregex '.*\\.\\(jpg\\|jpeg\\|png\\)$' | head -n 10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43wkyzoFHT69",
        "outputId": "cb948cc7-e670-4923-fb3d-4f6ce8df6284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counting images under exp/datasets (recursive)…\n",
            "41\n",
            "--- samples ---\n",
            "exp/datasets/ood/0/orig_4.png\n",
            "exp/datasets/ood/0/orig_0.png\n",
            "exp/datasets/ood/0/orig_2.png\n",
            "exp/datasets/ood/0/orig_3.png\n",
            "exp/datasets/ood/0/orig_5.png\n",
            "exp/datasets/ood/0/orig_1.png\n",
            "exp/datasets/ood_bedroom/0/orig_11.png\n",
            "exp/datasets/ood_bedroom/0/orig_4.png\n",
            "exp/datasets/ood_bedroom/0/orig_9.png\n",
            "exp/datasets/ood_bedroom/0/orig_7.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into 'ddrm-exp-datasets'...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -e\n",
        "cd /content/ddrm\n",
        "\n",
        "python - <<'PY'\n",
        "import os, glob\n",
        "from PIL import Image\n",
        "\n",
        "# Gather from all OOD roots, RECURSIVELY\n",
        "src_roots = [\n",
        "    \"exp/datasets/ood\",\n",
        "    \"exp/datasets/ood_bedroom\",\n",
        "    \"exp/datasets/ood_celeba\",\n",
        "    \"exp/datasets/ood_church_outdoor\",\n",
        "]\n",
        "all_files = []\n",
        "for root in src_roots:\n",
        "    for ext in ('*.jpg','*.jpeg','*.png','*.JPG','*.JPEG','*.PNG'):\n",
        "        all_files += glob.glob(os.path.join(root, '**', ext), recursive=True)\n",
        "all_files = sorted(set(all_files))\n",
        "print(\"Found\", len(all_files), \"source images.\")\n",
        "\n",
        "dst = \"exp/datasets/imagenet/imagenet\"\n",
        "os.makedirs(dst, exist_ok=True)\n",
        "\n",
        "names = []\n",
        "for i, f in enumerate(all_files[:1000], 1):\n",
        "    stem = f\"demo_{i:04d}\"         # IMPORTANT: list will contain stems (no extension)\n",
        "    outp = os.path.join(dst, stem + \".jpeg\")\n",
        "    try:\n",
        "        im = Image.open(f).convert(\"RGB\")\n",
        "        im.save(outp, \"JPEG\", quality=95)\n",
        "        names.append(stem)\n",
        "    except Exception as e:\n",
        "        print(\"skip:\", f, \"->\", e)\n",
        "\n",
        "# Write list WITHOUT extensions (loader appends .jpeg)\n",
        "os.makedirs(\"exp\", exist_ok=True)\n",
        "with open(\"exp/imagenet_val_1k.txt\",\"w\") as g:\n",
        "    for n in names:\n",
        "        g.write(n+\"\\n\")\n",
        "\n",
        "print(f\"Prepared {len(names)} jpeg images and wrote exp/imagenet_val_1k.txt\")\n",
        "print(\"First 5 list entries:\", names[:5])\n",
        "PY\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LXsaHfBIx6l",
        "outputId": "3585f100-16e9-4261-dbc5-997737c75ecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 41 source images.\n",
            "Prepared 41 jpeg images and wrote exp/imagenet_val_1k.txt\n",
            "First 5 list entries: ['demo_0001', 'demo_0002', 'demo_0003', 'demo_0004', 'demo_0005']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -e\n",
        "cd /content/ddrm\n",
        "\n",
        "# (optional) reduce thread warnings; the config may still spawn workers\n",
        "export OMP_NUM_THREADS=1 MKL_NUM_THREADS=1\n",
        "\n",
        "python main.py --ni --config imagenet_256.yml --doc imagenet \\\n",
        "  --timesteps 20 --eta 0.85 --etaB 1 --deg deblur_uni --sigma_0 0.0 -i demo_deblur\n",
        "\n",
        "python main.py --ni --config imagenet_256.yml --doc imagenet \\\n",
        "  --timesteps 40 --eta 0.85 --etaB 1 --deg sr4 --sigma_0 0.05 -i demo_sr4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxdkDtm3LsOA",
        "outputId": "4b0e89a6-c666-4de0-b084-0fc3d969f4b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building dataset from exp/imagenet_val_1k.txt\n",
            "read meta done\n",
            "Dataset has size 41\n",
            "Start from 0\n",
            "Total Average PSNR: 38.44\n",
            "Number of samples: 41\n",
            "building dataset from exp/imagenet_val_1k.txt\n",
            "read meta done\n",
            "Dataset has size 41\n",
            "Start from 0\n",
            "Total Average PSNR: 25.46\n",
            "Number of samples: 41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-09-23 15:13:06.013584: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1758640386.334161   10202 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1758640386.419597   10202 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1758640386.951395   10202 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758640386.951428   10202 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758640386.951431   10202 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758640386.951433   10202 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-23 15:13:06.956282: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "INFO - main.py - 2025-09-23 15:13:18,607 - Using device: cuda\n",
            "INFO - main.py - 2025-09-23 15:13:18,611 - Writing log file to exp/logs/imagenet\n",
            "INFO - main.py - 2025-09-23 15:13:18,611 - Exp instance id = 10202\n",
            "INFO - main.py - 2025-09-23 15:13:18,611 - Exp comment = \n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "\r  0%|          | 0/6 [00:00<?, ?it/s]\n",
            "\r0it [00:00, ?it/s]\u001b[A\n",
            "\r1it [00:08,  8.97s/it]\u001b[A\n",
            "\r2it [00:10,  4.55s/it]\u001b[A\n",
            "\r3it [00:11,  3.13s/it]\u001b[A\n",
            "\r4it [00:13,  2.46s/it]\u001b[A\n",
            "\r5it [00:14,  2.09s/it]\u001b[A\n",
            "\r6it [00:16,  1.87s/it]\u001b[A\n",
            "\r7it [00:17,  1.73s/it]\u001b[A\n",
            "\r8it [00:19,  1.64s/it]\u001b[A\n",
            "\r9it [00:20,  1.58s/it]\u001b[A\n",
            "\r10it [00:21,  1.54s/it]\u001b[A\n",
            "\r11it [00:23,  1.51s/it]\u001b[A\n",
            "\r12it [00:24,  1.50s/it]\u001b[A\n",
            "\r13it [00:26,  1.49s/it]\u001b[A\n",
            "\r14it [00:27,  1.48s/it]\u001b[A\n",
            "\r15it [00:29,  1.48s/it]\u001b[A\n",
            "\r16it [00:30,  1.48s/it]\u001b[A\n",
            "\r17it [00:32,  1.48s/it]\u001b[A\n",
            "\r18it [00:33,  1.48s/it]\u001b[A\n",
            "\r19it [00:35,  1.48s/it]\u001b[A\n",
            "\r20it [00:36,  1.48s/it]\u001b[A\r20it [00:36,  1.83s/it]\n",
            "\rPSNR: 39.88:   0%|          | 0/6 [00:39<?, ?it/s]\rPSNR: 39.88:  17%|█▋        | 1/6 [00:39<03:18, 39.73s/it]\n",
            "\r0it [00:00, ?it/s]\u001b[A\n",
            "\r1it [00:01,  1.48s/it]\u001b[A\n",
            "\r2it [00:02,  1.48s/it]\u001b[A\n",
            "\r3it [00:04,  1.48s/it]\u001b[A\n",
            "\r4it [00:05,  1.48s/it]\u001b[A\n",
            "\r5it [00:07,  1.48s/it]\u001b[A\n",
            "\r6it [00:08,  1.48s/it]\u001b[A\n",
            "\r7it [00:10,  1.49s/it]\u001b[A\n",
            "\r8it [00:11,  1.49s/it]\u001b[A\n",
            "\r9it [00:13,  1.50s/it]\u001b[A\n",
            "\r10it [00:14,  1.50s/it]\u001b[A\n",
            "\r11it [00:16,  1.51s/it]\u001b[A\n",
            "\r12it [00:17,  1.51s/it]\u001b[A\n",
            "\r13it [00:19,  1.52s/it]\u001b[A\n",
            "\r14it [00:21,  1.52s/it]\u001b[A\n",
            "\r15it [00:22,  1.53s/it]\u001b[A\n",
            "\r16it [00:24,  1.54s/it]\u001b[A\n",
            "\r17it [00:25,  1.54s/it]\u001b[A\n",
            "\r18it [00:27,  1.55s/it]\u001b[A\n",
            "\r19it [00:28,  1.55s/it]\u001b[A\n",
            "\r20it [00:30,  1.56s/it]\u001b[A\r20it [00:30,  1.52s/it]\n",
            "\rPSNR: 39.57:  17%|█▋        | 1/6 [01:11<03:18, 39.73s/it]\rPSNR: 39.57:  33%|███▎      | 2/6 [01:11<02:19, 34.76s/it]\n",
            "\r0it [00:00, ?it/s]\u001b[A\n",
            "\r1it [00:01,  1.57s/it]\u001b[A\n",
            "\r2it [00:03,  1.58s/it]\u001b[A\n",
            "\r3it [00:04,  1.58s/it]\u001b[A\n",
            "\r4it [00:06,  1.58s/it]\u001b[A\n",
            "\r5it [00:07,  1.58s/it]\u001b[A\n",
            "\r6it [00:09,  1.58s/it]\u001b[A\n",
            "\r7it [00:11,  1.58s/it]\u001b[A\n",
            "\r8it [00:12,  1.59s/it]\u001b[A\n",
            "\r9it [00:14,  1.59s/it]\u001b[A\n",
            "\r10it [00:15,  1.60s/it]\u001b[A\n",
            "\r11it [00:17,  1.61s/it]\u001b[A\n",
            "\r12it [00:19,  1.61s/it]\u001b[A\n",
            "\r13it [00:20,  1.62s/it]\u001b[A\n",
            "\r14it [00:22,  1.63s/it]\u001b[A\n",
            "\r15it [00:24,  1.64s/it]\u001b[A\n",
            "\r16it [00:25,  1.64s/it]\u001b[A\n",
            "\r17it [00:27,  1.65s/it]\u001b[A\n",
            "\r18it [00:29,  1.66s/it]\u001b[A\n",
            "\r19it [00:30,  1.67s/it]\u001b[A\n",
            "\r20it [00:32,  1.68s/it]\u001b[A\r20it [00:32,  1.62s/it]\n",
            "\rPSNR: 39.42:  33%|███▎      | 2/6 [01:44<02:19, 34.76s/it]\rPSNR: 39.42:  50%|█████     | 3/6 [01:44<01:42, 34.07s/it]\n",
            "\r0it [00:00, ?it/s]\u001b[A\n",
            "\r1it [00:01,  1.67s/it]\u001b[A\n",
            "\r2it [00:03,  1.69s/it]\u001b[A\n",
            "\r3it [00:05,  1.70s/it]\u001b[A\n",
            "\r4it [00:06,  1.70s/it]\u001b[A\n",
            "\r5it [00:08,  1.71s/it]\u001b[A\n",
            "\r6it [00:10,  1.71s/it]\u001b[A\n",
            "\r7it [00:11,  1.71s/it]\u001b[A\n",
            "\r8it [00:13,  1.72s/it]\u001b[A\n",
            "\r9it [00:15,  1.72s/it]\u001b[A\n",
            "\r10it [00:17,  1.71s/it]\u001b[A\n",
            "\r11it [00:18,  1.71s/it]\u001b[A\n",
            "\r12it [00:20,  1.70s/it]\u001b[A\n",
            "\r13it [00:22,  1.70s/it]\u001b[A\n",
            "\r14it [00:23,  1.69s/it]\u001b[A\n",
            "\r15it [00:25,  1.69s/it]\u001b[A\n",
            "\r16it [00:27,  1.68s/it]\u001b[A\n",
            "\r17it [00:28,  1.68s/it]\u001b[A\n",
            "\r18it [00:30,  1.67s/it]\u001b[A\n",
            "\r19it [00:32,  1.67s/it]\u001b[A\n",
            "\r20it [00:33,  1.66s/it]\u001b[A\r20it [00:33,  1.69s/it]\n",
            "\rPSNR: 38.54:  50%|█████     | 3/6 [02:18<01:42, 34.07s/it]\rPSNR: 38.54:  67%|██████▋   | 4/6 [02:18<01:08, 34.31s/it]\n",
            "\r0it [00:00, ?it/s]\u001b[A\n",
            "\r1it [00:01,  1.62s/it]\u001b[A\n",
            "\r2it [00:03,  1.63s/it]\u001b[A\n",
            "\r3it [00:04,  1.63s/it]\u001b[A\n",
            "\r4it [00:06,  1.63s/it]\u001b[A\n",
            "\r5it [00:08,  1.63s/it]\u001b[A\n",
            "\r6it [00:09,  1.62s/it]\u001b[A\n",
            "\r7it [00:11,  1.62s/it]\u001b[A\n",
            "\r8it [00:13,  1.62s/it]\u001b[A\n",
            "\r9it [00:14,  1.63s/it]\u001b[A\n",
            "\r10it [00:16,  1.62s/it]\u001b[A\n",
            "\r11it [00:17,  1.62s/it]\u001b[A\n",
            "\r12it [00:19,  1.62s/it]\u001b[A\n",
            "\r13it [00:21,  1.63s/it]\u001b[A\n",
            "\r14it [00:22,  1.63s/it]\u001b[A\n",
            "\r15it [00:24,  1.63s/it]\u001b[A\n",
            "\r16it [00:26,  1.63s/it]\u001b[A\n",
            "\r17it [00:27,  1.63s/it]\u001b[A\n",
            "\r18it [00:29,  1.63s/it]\u001b[A\n",
            "\r19it [00:30,  1.63s/it]\u001b[A\n",
            "\r20it [00:32,  1.63s/it]\u001b[A\r20it [00:32,  1.63s/it]\n",
            "\rPSNR: 38.35:  67%|██████▋   | 4/6 [02:52<01:08, 34.31s/it]\rPSNR: 38.35:  83%|████████▎ | 5/6 [02:52<00:33, 34.00s/it]\n",
            "\r0it [00:00, ?it/s]\u001b[A\n",
            "\r1it [00:01,  1.50s/it]\u001b[A\n",
            "\r2it [00:01,  1.33it/s]\u001b[A\n",
            "\r3it [00:01,  1.95it/s]\u001b[A\n",
            "\r4it [00:02,  2.50it/s]\u001b[A\n",
            "\r5it [00:02,  2.92it/s]\u001b[A\n",
            "\r6it [00:02,  3.26it/s]\u001b[A\n",
            "\r7it [00:02,  3.56it/s]\u001b[A\n",
            "\r8it [00:03,  3.80it/s]\u001b[A\n",
            "\r9it [00:03,  3.97it/s]\u001b[A\n",
            "\r10it [00:03,  4.03it/s]\u001b[A\n",
            "\r11it [00:03,  4.11it/s]\u001b[A\n",
            "\r12it [00:04,  4.18it/s]\u001b[A\n",
            "\r13it [00:04,  4.25it/s]\u001b[A\n",
            "\r14it [00:04,  4.24it/s]\u001b[A\n",
            "\r15it [00:04,  4.22it/s]\u001b[A\n",
            "\r16it [00:04,  4.26it/s]\u001b[A\n",
            "\r17it [00:05,  4.27it/s]\u001b[A\n",
            "\r18it [00:05,  4.28it/s]\u001b[A\n",
            "\r19it [00:05,  4.26it/s]\u001b[A\n",
            "\r20it [00:05,  4.24it/s]\u001b[A\r20it [00:05,  3.38it/s]\n",
            "\rPSNR: 38.44:  83%|████████▎ | 5/6 [02:58<00:33, 34.00s/it]\rPSNR: 38.44: 100%|██████████| 6/6 [02:58<00:00, 24.49s/it]\rPSNR: 38.44: 100%|██████████| 6/6 [02:59<00:00, 29.90s/it]\n",
            "2025-09-23 15:16:45.450587: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1758640605.469782   11224 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1758640605.475680   11224 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1758640605.491361   11224 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758640605.491387   11224 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758640605.491389   11224 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758640605.491391   11224 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-23 15:16:45.495891: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "INFO - main.py - 2025-09-23 15:16:51,774 - Using device: cuda\n",
            "INFO - main.py - 2025-09-23 15:16:51,776 - Writing log file to exp/logs/imagenet\n",
            "INFO - main.py - 2025-09-23 15:16:51,776 - Exp instance id = 11224\n",
            "INFO - main.py - 2025-09-23 15:16:51,776 - Exp comment = \n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "\r  0%|          | 0/6 [00:00<?, ?it/s]\n",
            "\r0it [00:00, ?it/s]\u001b[A\n",
            "\r1it [00:09,  9.53s/it]\u001b[A\n",
            "\r2it [00:11,  4.91s/it]\u001b[A\n",
            "\r3it [00:12,  3.43s/it]\u001b[A\n",
            "\r4it [00:14,  2.74s/it]\u001b[A\n",
            "\r5it [00:16,  2.36s/it]\u001b[A\n",
            "\r6it [00:17,  2.14s/it]\u001b[A\n",
            "\r7it [00:19,  2.00s/it]\u001b[A\n",
            "\r8it [00:21,  1.91s/it]\u001b[A\n",
            "\r9it [00:23,  1.85s/it]\u001b[A\n",
            "\r10it [00:24,  1.82s/it]\u001b[A\n",
            "\r11it [00:26,  1.80s/it]\u001b[A\n",
            "\r12it [00:28,  1.78s/it]\u001b[A\n",
            "\r13it [00:30,  1.78s/it]\u001b[A\n",
            "\r14it [00:31,  1.77s/it]\u001b[A\n",
            "\r15it [00:33,  1.77s/it]\u001b[A\n",
            "\r16it [00:35,  1.76s/it]\u001b[A\n",
            "\r17it [00:37,  1.76s/it]\u001b[A\n",
            "\r18it [00:38,  1.75s/it]\u001b[A\n",
            "\r19it [00:40,  1.74s/it]\u001b[A\n",
            "\r20it [00:42,  1.73s/it]\u001b[A\r20it [00:42,  2.11s/it]\n",
            "\rPSNR: 26.23:   0%|          | 0/6 [00:44<?, ?it/s]\rPSNR: 26.23:  17%|█▋        | 1/6 [00:44<03:41, 44.30s/it]\n",
            "\r0it [00:00, ?it/s]\u001b[A\n",
            "\r1it [00:01,  1.69s/it]\u001b[A\n",
            "\r2it [00:03,  1.69s/it]\u001b[A\n",
            "\r3it [00:05,  1.68s/it]\u001b[A\n",
            "\r4it [00:06,  1.67s/it]\u001b[A\n",
            "\r5it [00:08,  1.67s/it]\u001b[A\n",
            "\r6it [00:10,  1.67s/it]\u001b[A\n",
            "\r7it [00:11,  1.66s/it]\u001b[A\n",
            "\r8it [00:13,  1.66s/it]\u001b[A\n",
            "\r9it [00:14,  1.65s/it]\u001b[A\n",
            "\r10it [00:16,  1.65s/it]\u001b[A\n",
            "\r11it [00:18,  1.65s/it]\u001b[A\n",
            "\r12it [00:19,  1.64s/it]\u001b[A\n",
            "\r13it [00:21,  1.64s/it]\u001b[A\n",
            "\r14it [00:23,  1.64s/it]\u001b[A\n",
            "\r15it [00:24,  1.64s/it]\u001b[A\n",
            "\r16it [00:26,  1.64s/it]\u001b[A\n",
            "\r17it [00:28,  1.64s/it]\u001b[A\n",
            "\r18it [00:29,  1.64s/it]\u001b[A\n",
            "\r19it [00:31,  1.64s/it]\u001b[A\n",
            "\r20it [00:32,  1.63s/it]\u001b[A\r20it [00:32,  1.65s/it]\n",
            "\rPSNR: 26.29:  17%|█▋        | 1/6 [01:17<03:41, 44.30s/it]\rPSNR: 26.29:  33%|███▎      | 2/6 [01:17<02:31, 37.99s/it]\n",
            "\r0it [00:00, ?it/s]\u001b[A\n",
            "\r1it [00:01,  1.61s/it]\u001b[A\n",
            "\r2it [00:03,  1.63s/it]\u001b[A\n",
            "\r3it [00:04,  1.63s/it]\u001b[A\n",
            "\r4it [00:06,  1.63s/it]\u001b[A\n",
            "\r5it [00:08,  1.64s/it]\u001b[A\n",
            "\r6it [00:09,  1.64s/it]\u001b[A\n",
            "\r7it [00:11,  1.64s/it]\u001b[A\n",
            "\r8it [00:13,  1.64s/it]\u001b[A\n",
            "\r9it [00:14,  1.64s/it]\u001b[A\n",
            "\r10it [00:16,  1.65s/it]\u001b[A\n",
            "\r11it [00:18,  1.65s/it]\u001b[A\n",
            "\r12it [00:19,  1.65s/it]\u001b[A\n",
            "\r13it [00:21,  1.65s/it]\u001b[A\n",
            "\r14it [00:23,  1.66s/it]\u001b[A\n",
            "\r15it [00:24,  1.66s/it]\u001b[A\n",
            "\r16it [00:26,  1.67s/it]\u001b[A\n",
            "\r17it [00:28,  1.67s/it]\u001b[A\n",
            "\r18it [00:29,  1.67s/it]\u001b[A\n",
            "\r19it [00:31,  1.67s/it]\u001b[A\n",
            "\r20it [00:33,  1.67s/it]\u001b[A\r20it [00:33,  1.65s/it]\n",
            "\rPSNR: 26.16:  33%|███▎      | 2/6 [01:51<02:31, 37.99s/it]\rPSNR: 26.16:  50%|█████     | 3/6 [01:51<01:47, 35.98s/it]\n",
            "\r0it [00:00, ?it/s]\u001b[A\n",
            "\r1it [00:01,  1.67s/it]\u001b[A\n",
            "\r2it [00:03,  1.68s/it]\u001b[A\n",
            "\r3it [00:05,  1.68s/it]\u001b[A\n",
            "\r4it [00:06,  1.67s/it]\u001b[A\n",
            "\r5it [00:08,  1.68s/it]\u001b[A\n",
            "\r6it [00:10,  1.68s/it]\u001b[A\n",
            "\r7it [00:11,  1.68s/it]\u001b[A\n",
            "\r8it [00:13,  1.68s/it]\u001b[A\n",
            "\r9it [00:15,  1.68s/it]\u001b[A\n",
            "\r10it [00:16,  1.68s/it]\u001b[A\n",
            "\r11it [00:18,  1.68s/it]\u001b[A\n",
            "\r12it [00:20,  1.68s/it]\u001b[A\n",
            "\r13it [00:21,  1.68s/it]\u001b[A\n",
            "\r14it [00:23,  1.68s/it]\u001b[A\n",
            "\r15it [00:25,  1.67s/it]\u001b[A\n",
            "\r16it [00:26,  1.67s/it]\u001b[A\n",
            "\r17it [00:28,  1.67s/it]\u001b[A\n",
            "\r18it [00:30,  1.67s/it]\u001b[A\n",
            "\r19it [00:31,  1.67s/it]\u001b[A\n",
            "\r20it [00:33,  1.67s/it]\u001b[A\r20it [00:33,  1.67s/it]\n",
            "\rPSNR: 25.46:  50%|█████     | 3/6 [02:25<01:47, 35.98s/it]\rPSNR: 25.46:  67%|██████▋   | 4/6 [02:25<01:10, 35.20s/it]\n",
            "\r0it [00:00, ?it/s]\u001b[A\n",
            "\r1it [00:01,  1.62s/it]\u001b[A\n",
            "\r2it [00:03,  1.64s/it]\u001b[A\n",
            "\r3it [00:04,  1.64s/it]\u001b[A\n",
            "\r4it [00:06,  1.65s/it]\u001b[A\n",
            "\r5it [00:08,  1.65s/it]\u001b[A\n",
            "\r6it [00:09,  1.65s/it]\u001b[A\n",
            "\r7it [00:11,  1.65s/it]\u001b[A\n",
            "\r8it [00:13,  1.65s/it]\u001b[A\n",
            "\r9it [00:14,  1.65s/it]\u001b[A\n",
            "\r10it [00:16,  1.65s/it]\u001b[A\n",
            "\r11it [00:18,  1.65s/it]\u001b[A\n",
            "\r12it [00:19,  1.65s/it]\u001b[A\n",
            "\r13it [00:21,  1.65s/it]\u001b[A\n",
            "\r14it [00:23,  1.65s/it]\u001b[A\n",
            "\r15it [00:24,  1.65s/it]\u001b[A\n",
            "\r16it [00:26,  1.66s/it]\u001b[A\n",
            "\r17it [00:28,  1.66s/it]\u001b[A\n",
            "\r18it [00:29,  1.66s/it]\u001b[A\n",
            "\r19it [00:31,  1.66s/it]\u001b[A\n",
            "\r20it [00:33,  1.66s/it]\u001b[A\r20it [00:33,  1.65s/it]\n",
            "\rPSNR: 25.39:  67%|██████▋   | 4/6 [02:59<01:10, 35.20s/it]\rPSNR: 25.39:  83%|████████▎ | 5/6 [02:59<00:34, 34.60s/it]\n",
            "\r0it [00:00, ?it/s]\u001b[A\n",
            "\r1it [00:01,  1.42s/it]\u001b[A\n",
            "\r2it [00:01,  1.38it/s]\u001b[A\n",
            "\r3it [00:01,  2.00it/s]\u001b[A\n",
            "\r4it [00:02,  2.54it/s]\u001b[A\n",
            "\r5it [00:02,  2.94it/s]\u001b[A\n",
            "\r6it [00:02,  3.28it/s]\u001b[A\n",
            "\r7it [00:02,  3.57it/s]\u001b[A\n",
            "\r8it [00:03,  3.78it/s]\u001b[A\n",
            "\r9it [00:03,  3.93it/s]\u001b[A\n",
            "\r10it [00:03,  3.99it/s]\u001b[A\n",
            "\r11it [00:03,  4.06it/s]\u001b[A\n",
            "\r12it [00:04,  4.13it/s]\u001b[A\n",
            "\r13it [00:04,  4.17it/s]\u001b[A\n",
            "\r14it [00:04,  4.21it/s]\u001b[A\n",
            "\r15it [00:04,  4.21it/s]\u001b[A\n",
            "\r16it [00:04,  4.24it/s]\u001b[A\n",
            "\r17it [00:05,  4.25it/s]\u001b[A\n",
            "\r18it [00:05,  4.29it/s]\u001b[A\n",
            "\r19it [00:05,  4.28it/s]\u001b[A\n",
            "\r20it [00:05,  4.29it/s]\u001b[A\r20it [00:05,  3.41it/s]\n",
            "\rPSNR: 25.46:  83%|████████▎ | 5/6 [03:04<00:34, 34.60s/it]\rPSNR: 25.46: 100%|██████████| 6/6 [03:04<00:00, 24.86s/it]\rPSNR: 25.46: 100%|██████████| 6/6 [03:05<00:00, 30.93s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-M5MFpuN3OV",
        "outputId": "a46832a8-88db-4bc0-8618-b8ff3c4d86a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ddrm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# set -e\n",
        "# cd /content/ddrm\n",
        "\n",
        "python main.py --ni --config imagenet_256.yml --doc imagenet \\\n",
        "  --timesteps 40 --eta 0.85 --etaB 1 --deg sr4 --sigma_0 0.05 -i demo_sr4_iter40\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjnBzUFxNpfc",
        "outputId": "8dad3023-e3c4-4823-d4ce-cc4d17dc72df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building dataset from exp/imagenet_val_1k.txt\n",
            "read meta done\n",
            "Dataset has size 41\n",
            "Start from 0\n",
            "Total Average PSNR: 25.66\n",
            "Number of samples: 41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-09-23 15:36:14.942621: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1758641774.963742   16258 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1758641774.970074   16258 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1758641774.986658   16258 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758641774.986686   16258 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758641774.986689   16258 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758641774.986693   16258 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-23 15:36:14.991753: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "INFO - main.py - 2025-09-23 15:36:20,352 - Using device: cuda\n",
            "INFO - main.py - 2025-09-23 15:36:20,353 - Writing log file to exp/logs/imagenet\n",
            "INFO - main.py - 2025-09-23 15:36:20,353 - Exp instance id = 16258\n",
            "INFO - main.py - 2025-09-23 15:36:20,353 - Exp comment = \n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "\r  0%|          | 0/6 [00:00<?, ?it/s]\n",
            "\r0it [00:00, ?it/s]\u001b[A\n",
            "\r1it [00:08,  8.18s/it]\u001b[A\n",
            "\r2it [00:09,  4.22s/it]\u001b[A\n",
            "\r3it [00:11,  2.95s/it]\u001b[A\n",
            "\r4it [00:12,  2.35s/it]\u001b[A\n",
            "\r5it [00:13,  2.02s/it]\u001b[A\n",
            "\r6it [00:15,  1.82s/it]\u001b[A\n",
            "\r7it [00:16,  1.70s/it]\u001b[A\n",
            "\r8it [00:18,  1.62s/it]\u001b[A\n",
            "\r9it [00:19,  1.56s/it]\u001b[A\n",
            "\r10it [00:21,  1.52s/it]\u001b[A\n",
            "\r11it [00:22,  1.50s/it]\u001b[A\n",
            "\r12it [00:24,  1.48s/it]\u001b[A\n",
            "\r13it [00:25,  1.47s/it]\u001b[A\n",
            "\r14it [00:26,  1.47s/it]\u001b[A\n",
            "\r15it [00:28,  1.47s/it]\u001b[A\n",
            "\r16it [00:29,  1.47s/it]\u001b[A\n",
            "\r17it [00:31,  1.46s/it]\u001b[A\n",
            "\r18it [00:32,  1.47s/it]\u001b[A\n",
            "\r19it [00:34,  1.47s/it]\u001b[A\n",
            "\r20it [00:35,  1.47s/it]\u001b[A\n",
            "\r21it [00:37,  1.48s/it]\u001b[A\n",
            "\r22it [00:38,  1.48s/it]\u001b[A\n",
            "\r23it [00:40,  1.48s/it]\u001b[A\n",
            "\r24it [00:41,  1.49s/it]\u001b[A\n",
            "\r25it [00:43,  1.49s/it]\u001b[A\n",
            "\r26it [00:44,  1.49s/it]\u001b[A\n",
            "\r27it [00:46,  1.49s/it]\u001b[A\n",
            "\r28it [00:47,  1.49s/it]\u001b[A\n",
            "\r29it [00:49,  1.50s/it]\u001b[A\n",
            "\r30it [00:50,  1.50s/it]\u001b[A\n",
            "\r31it [00:52,  1.50s/it]\u001b[A\n",
            "\r32it [00:53,  1.51s/it]\u001b[A\n",
            "\r33it [00:55,  1.51s/it]\u001b[A\n",
            "\r34it [00:56,  1.52s/it]\u001b[A\n",
            "\r35it [00:58,  1.52s/it]\u001b[A\n",
            "\r36it [00:59,  1.53s/it]\u001b[A\n",
            "\r37it [01:01,  1.54s/it]\u001b[A\n",
            "\r38it [01:02,  1.54s/it]\u001b[A\n",
            "\r39it [01:04,  1.55s/it]\u001b[A\n",
            "\r40it [01:06,  1.55s/it]\u001b[A\r40it [01:06,  1.65s/it]\n",
            "\rPSNR: 26.38:   0%|          | 0/6 [01:08<?, ?it/s]\rPSNR: 26.38:  17%|█▋        | 1/6 [01:08<05:40, 68.03s/it]\n",
            "\r0it [00:00, ?it/s]\u001b[A\n",
            "\r1it [00:01,  1.55s/it]\u001b[A\n",
            "\r2it [00:03,  1.57s/it]\u001b[A\n",
            "\r3it [00:04,  1.57s/it]\u001b[A\n",
            "\r4it [00:06,  1.57s/it]\u001b[A\n",
            "\r5it [00:07,  1.58s/it]\u001b[A\n",
            "\r6it [00:09,  1.59s/it]\u001b[A\n",
            "\r7it [00:11,  1.59s/it]\u001b[A\n",
            "\r8it [00:12,  1.59s/it]\u001b[A\n",
            "\r9it [00:14,  1.59s/it]\u001b[A\n",
            "\r10it [00:15,  1.59s/it]\u001b[A\n",
            "\r11it [00:17,  1.60s/it]\u001b[A\n",
            "\r12it [00:19,  1.60s/it]\u001b[A\n",
            "\r13it [00:20,  1.61s/it]\u001b[A\n",
            "\r14it [00:22,  1.61s/it]\u001b[A\n",
            "\r15it [00:23,  1.62s/it]\u001b[A\n",
            "\r16it [00:25,  1.63s/it]\u001b[A\n",
            "\r17it [00:27,  1.63s/it]\u001b[A\n",
            "\r18it [00:28,  1.64s/it]\u001b[A\n",
            "\r19it [00:30,  1.65s/it]\u001b[A\n",
            "\r20it [00:32,  1.66s/it]\u001b[A\n",
            "\r21it [00:33,  1.67s/it]\u001b[A\n",
            "\r22it [00:35,  1.67s/it]\u001b[A\n",
            "\r23it [00:37,  1.68s/it]\u001b[A\n",
            "\r24it [00:39,  1.69s/it]\u001b[A\n",
            "\r25it [00:40,  1.70s/it]\u001b[A\n",
            "\r26it [00:42,  1.71s/it]\u001b[A\n",
            "\r27it [00:44,  1.71s/it]\u001b[A\n",
            "\r28it [00:45,  1.72s/it]\u001b[A\n",
            "\r29it [00:47,  1.72s/it]\u001b[A\n",
            "\r30it [00:49,  1.72s/it]\u001b[A\n",
            "\r31it [00:51,  1.71s/it]\u001b[A\n",
            "\r32it [00:52,  1.71s/it]\u001b[A\n",
            "\r33it [00:54,  1.70s/it]\u001b[A\n",
            "\r34it [00:56,  1.70s/it]\u001b[A\n",
            "\r35it [00:57,  1.69s/it]\u001b[A\n",
            "\r36it [00:59,  1.69s/it]\u001b[A\n",
            "\r37it [01:01,  1.68s/it]\u001b[A\n",
            "\r38it [01:02,  1.67s/it]\u001b[A\n",
            "\r39it [01:04,  1.67s/it]\u001b[A\n",
            "\r40it [01:06,  1.67s/it]\u001b[A\r40it [01:06,  1.65s/it]\n",
            "\rPSNR: 26.48:  17%|█▋        | 1/6 [02:14<05:40, 68.03s/it]\rPSNR: 26.48:  33%|███▎      | 2/6 [02:14<04:29, 67.26s/it]\n",
            "\r0it [00:00, ?it/s]\u001b[A\n",
            "\r1it [00:01,  1.61s/it]\u001b[A\n",
            "\r2it [00:03,  1.64s/it]\u001b[A\n",
            "\r3it [00:04,  1.63s/it]\u001b[A\n",
            "\r4it [00:06,  1.63s/it]\u001b[A\n",
            "\r5it [00:08,  1.63s/it]\u001b[A\n",
            "\r6it [00:09,  1.63s/it]\u001b[A\n",
            "\r7it [00:11,  1.63s/it]\u001b[A\n",
            "\r8it [00:13,  1.62s/it]\u001b[A\n",
            "\r9it [00:14,  1.62s/it]\u001b[A\n",
            "\r10it [00:16,  1.62s/it]\u001b[A\n",
            "\r11it [00:17,  1.62s/it]\u001b[A\n",
            "\r12it [00:19,  1.62s/it]\u001b[A\n",
            "\r13it [00:21,  1.62s/it]\u001b[A\n",
            "\r14it [00:22,  1.62s/it]\u001b[A\n",
            "\r15it [00:24,  1.62s/it]\u001b[A\n",
            "\r16it [00:25,  1.62s/it]\u001b[A\n",
            "\r17it [00:27,  1.62s/it]\u001b[A\n",
            "\r18it [00:29,  1.62s/it]\u001b[A\n",
            "\r19it [00:30,  1.62s/it]\u001b[A\n",
            "\r20it [00:32,  1.62s/it]\u001b[A\n",
            "\r21it [00:34,  1.62s/it]\u001b[A\n",
            "\r22it [00:35,  1.62s/it]\u001b[A\n",
            "\r23it [00:37,  1.63s/it]\u001b[A\n",
            "\r24it [00:38,  1.63s/it]\u001b[A\n",
            "\r25it [00:40,  1.63s/it]\u001b[A\n",
            "\r26it [00:42,  1.63s/it]\u001b[A\n",
            "\r27it [00:43,  1.63s/it]\u001b[A\n",
            "\r28it [00:45,  1.64s/it]\u001b[A\n",
            "\r29it [00:47,  1.64s/it]\u001b[A\n",
            "\r30it [00:48,  1.64s/it]\u001b[A\n",
            "\r31it [00:50,  1.64s/it]\u001b[A\n",
            "\r32it [00:52,  1.64s/it]\u001b[A\n",
            "\r33it [00:53,  1.64s/it]\u001b[A\n",
            "\r34it [00:55,  1.65s/it]\u001b[A\n",
            "\r35it [00:57,  1.65s/it]\u001b[A\n",
            "\r36it [00:58,  1.65s/it]\u001b[A\n",
            "\r37it [01:00,  1.65s/it]\u001b[A\n",
            "\r38it [01:02,  1.65s/it]\u001b[A\n",
            "\r39it [01:03,  1.65s/it]\u001b[A\n",
            "\r40it [01:05,  1.65s/it]\u001b[A\r40it [01:05,  1.63s/it]\n",
            "\rPSNR: 26.39:  33%|███▎      | 2/6 [03:20<04:29, 67.26s/it]\rPSNR: 26.39:  50%|█████     | 3/6 [03:20<03:20, 66.68s/it]\n",
            "\r0it [00:00, ?it/s]\u001b[A\n",
            "\r1it [00:01,  1.66s/it]\u001b[A\n",
            "\r2it [00:03,  1.66s/it]\u001b[A\n",
            "\r3it [00:04,  1.65s/it]\u001b[A\n",
            "\r4it [00:06,  1.65s/it]\u001b[A\n",
            "\r5it [00:08,  1.65s/it]\u001b[A\n",
            "\r6it [00:09,  1.65s/it]\u001b[A\n",
            "\r7it [00:11,  1.65s/it]\u001b[A\n",
            "\r8it [00:13,  1.65s/it]\u001b[A\n",
            "\r9it [00:14,  1.65s/it]\u001b[A\n",
            "\r10it [00:16,  1.65s/it]\u001b[A\n",
            "\r11it [00:18,  1.64s/it]\u001b[A\n",
            "\r12it [00:19,  1.64s/it]\u001b[A\n",
            "\r13it [00:21,  1.64s/it]\u001b[A\n",
            "\r14it [00:23,  1.64s/it]\u001b[A\n",
            "\r15it [00:24,  1.64s/it]\u001b[A\n",
            "\r16it [00:26,  1.64s/it]\u001b[A\n",
            "\r17it [00:27,  1.64s/it]\u001b[A\n",
            "\r18it [00:29,  1.65s/it]\u001b[A\n",
            "\r19it [00:31,  1.64s/it]\u001b[A\n",
            "\r20it [00:32,  1.64s/it]\u001b[A\n",
            "\r21it [00:34,  1.64s/it]\u001b[A\n",
            "\r22it [00:36,  1.64s/it]\u001b[A\n",
            "\r23it [00:37,  1.64s/it]\u001b[A\n",
            "\r24it [00:39,  1.64s/it]\u001b[A\n",
            "\r25it [00:41,  1.64s/it]\u001b[A\n",
            "\r26it [00:42,  1.64s/it]\u001b[A\n",
            "\r27it [00:44,  1.64s/it]\u001b[A\n",
            "\r28it [00:46,  1.64s/it]\u001b[A\n",
            "\r29it [00:47,  1.64s/it]\u001b[A\n",
            "\r30it [00:49,  1.64s/it]\u001b[A\n",
            "\r31it [00:50,  1.64s/it]\u001b[A\n",
            "\r32it [00:52,  1.64s/it]\u001b[A\n",
            "\r33it [00:54,  1.64s/it]\u001b[A\n",
            "\r34it [00:55,  1.64s/it]\u001b[A\n",
            "\r35it [00:57,  1.64s/it]\u001b[A\n",
            "\r36it [00:59,  1.64s/it]\u001b[A\n",
            "\r37it [01:00,  1.64s/it]\u001b[A\n",
            "\r38it [01:02,  1.64s/it]\u001b[A\n",
            "\r39it [01:04,  1.64s/it]\u001b[A\n",
            "\r40it [01:05,  1.64s/it]\u001b[A\r40it [01:05,  1.64s/it]\n",
            "\rPSNR: 25.68:  50%|█████     | 3/6 [04:27<03:20, 66.68s/it]\rPSNR: 25.68:  67%|██████▋   | 4/6 [04:27<02:13, 66.54s/it]\n",
            "\r0it [00:00, ?it/s]\u001b[A\n",
            "\r1it [00:01,  1.60s/it]\u001b[A\n",
            "\r2it [00:03,  1.63s/it]\u001b[A\n",
            "\r3it [00:04,  1.63s/it]\u001b[A\n",
            "\r4it [00:06,  1.63s/it]\u001b[A\n",
            "\r5it [00:08,  1.63s/it]\u001b[A\n",
            "\r6it [00:09,  1.63s/it]\u001b[A\n",
            "\r7it [00:11,  1.63s/it]\u001b[A\n",
            "\r8it [00:13,  1.63s/it]\u001b[A\n",
            "\r9it [00:14,  1.64s/it]\u001b[A\n",
            "\r10it [00:16,  1.64s/it]\u001b[A\n",
            "\r11it [00:17,  1.64s/it]\u001b[A\n",
            "\r12it [00:19,  1.64s/it]\u001b[A\n",
            "\r13it [00:21,  1.64s/it]\u001b[A\n",
            "\r14it [00:22,  1.64s/it]\u001b[A\n",
            "\r15it [00:24,  1.64s/it]\u001b[A\n",
            "\r16it [00:26,  1.64s/it]\u001b[A\n",
            "\r17it [00:27,  1.65s/it]\u001b[A\n",
            "\r18it [00:29,  1.65s/it]\u001b[A\n",
            "\r19it [00:31,  1.65s/it]\u001b[A\n",
            "\r20it [00:32,  1.65s/it]\u001b[A\n",
            "\r21it [00:34,  1.65s/it]\u001b[A\n",
            "\r22it [00:36,  1.65s/it]\u001b[A\n",
            "\r23it [00:37,  1.65s/it]\u001b[A\n",
            "\r24it [00:39,  1.65s/it]\u001b[A\n",
            "\r25it [00:41,  1.65s/it]\u001b[A\n",
            "\r26it [00:42,  1.65s/it]\u001b[A\n",
            "\r27it [00:44,  1.65s/it]\u001b[A\n",
            "\r28it [00:46,  1.65s/it]\u001b[A\n",
            "\r29it [00:47,  1.65s/it]\u001b[A\n",
            "\r30it [00:49,  1.65s/it]\u001b[A\n",
            "\r31it [00:50,  1.65s/it]\u001b[A\n",
            "\r32it [00:52,  1.65s/it]\u001b[A\n",
            "\r33it [00:54,  1.65s/it]\u001b[A\n",
            "\r34it [00:55,  1.65s/it]\u001b[A\n",
            "\r35it [00:57,  1.65s/it]\u001b[A\n",
            "\r36it [00:59,  1.65s/it]\u001b[A\n",
            "\r37it [01:00,  1.65s/it]\u001b[A\n",
            "\r38it [01:02,  1.65s/it]\u001b[A\n",
            "\r39it [01:04,  1.64s/it]\u001b[A\n",
            "\r40it [01:05,  1.64s/it]\u001b[A\r40it [01:05,  1.64s/it]\n",
            "\rPSNR: 25.60:  67%|██████▋   | 4/6 [05:33<02:13, 66.54s/it]\rPSNR: 25.60:  83%|████████▎ | 5/6 [05:33<01:06, 66.47s/it]\n",
            "\r0it [00:00, ?it/s]\u001b[A\n",
            "\r1it [00:01,  1.40s/it]\u001b[A\n",
            "\r2it [00:01,  1.41it/s]\u001b[A\n",
            "\r3it [00:01,  2.05it/s]\u001b[A\n",
            "\r4it [00:02,  2.60it/s]\u001b[A\n",
            "\r5it [00:02,  3.01it/s]\u001b[A\n",
            "\r6it [00:02,  3.35it/s]\u001b[A\n",
            "\r7it [00:02,  3.65it/s]\u001b[A\n",
            "\r8it [00:02,  3.88it/s]\u001b[A\n",
            "\r9it [00:03,  4.02it/s]\u001b[A\n",
            "\r10it [00:03,  4.08it/s]\u001b[A\n",
            "\r11it [00:03,  4.16it/s]\u001b[A\n",
            "\r12it [00:03,  4.24it/s]\u001b[A\n",
            "\r13it [00:04,  4.27it/s]\u001b[A\n",
            "\r14it [00:04,  4.27it/s]\u001b[A\n",
            "\r15it [00:04,  4.28it/s]\u001b[A\n",
            "\r16it [00:04,  4.29it/s]\u001b[A\n",
            "\r17it [00:05,  4.32it/s]\u001b[A\n",
            "\r18it [00:05,  4.33it/s]\u001b[A\n",
            "\r19it [00:05,  4.33it/s]\u001b[A\n",
            "\r20it [00:05,  4.33it/s]\u001b[A\n",
            "\r21it [00:05,  4.32it/s]\u001b[A\n",
            "\r22it [00:06,  4.35it/s]\u001b[A\n",
            "\r23it [00:06,  4.35it/s]\u001b[A\n",
            "\r24it [00:06,  4.33it/s]\u001b[A\n",
            "\r25it [00:06,  4.34it/s]\u001b[A\n",
            "\r26it [00:07,  4.33it/s]\u001b[A\n",
            "\r27it [00:07,  4.36it/s]\u001b[A\n",
            "\r28it [00:07,  4.36it/s]\u001b[A\n",
            "\r29it [00:07,  4.34it/s]\u001b[A\n",
            "\r30it [00:08,  4.36it/s]\u001b[A\n",
            "\r31it [00:08,  4.37it/s]\u001b[A\n",
            "\r32it [00:08,  4.37it/s]\u001b[A\n",
            "\r33it [00:08,  4.37it/s]\u001b[A\n",
            "\r34it [00:08,  4.36it/s]\u001b[A\n",
            "\r35it [00:09,  4.34it/s]\u001b[A\n",
            "\r36it [00:09,  4.37it/s]\u001b[A\n",
            "\r37it [00:09,  4.37it/s]\u001b[A\n",
            "\r38it [00:09,  4.36it/s]\u001b[A\n",
            "\r39it [00:10,  4.36it/s]\u001b[A\n",
            "\r40it [00:10,  4.37it/s]\u001b[A\r40it [00:10,  3.86it/s]\n",
            "\rPSNR: 25.66:  83%|████████▎ | 5/6 [05:43<01:06, 66.47s/it]\rPSNR: 25.66: 100%|██████████| 6/6 [05:43<00:00, 47.42s/it]\rPSNR: 25.66: 100%|██████████| 6/6 [05:44<00:00, 57.41s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # 1) Mount Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# 2) Set source (your outputs) and destination (in Drive)\n",
        "src = \"/content/ddrm/exp/image_samples\"          # whole outputs folder\n",
        "dst = \"/content/drive/MyDrive/ddrm_results\"      # change if you want\n",
        "\n",
        "# 3) Copy (overwrites files with same names)\n",
        "import shutil, os\n",
        "os.makedirs(dst, exist_ok=True)\n",
        "shutil.copytree(src, dst, dirs_exist_ok=True)\n",
        "print(\"Copied to:\", dst)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hl6Gg9tUMFVX",
        "outputId": "120bab1f-d7bc-45d1-c928-d22b4dbd8251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copied to: /content/drive/MyDrive/ddrm_results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # 1) Mount Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# 2) Set source (your outputs) and destination (in Drive)\n",
        "src = \"/content/ddrm/exp/image_samples/demo_sr4_iter40\"          # whole outputs folder\n",
        "dst = \"/content/drive/MyDrive/ddrm_results/demo_sr4_iter40\"      # change if you want\n",
        "\n",
        "# 3) Copy (overwrites files with same names)\n",
        "import shutil, os\n",
        "os.makedirs(dst, exist_ok=True)\n",
        "shutil.copytree(src, dst, dirs_exist_ok=True)\n",
        "print(\"Copied to:\", dst)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvFGwdFNP6hp",
        "outputId": "37d79072-a151-4e39-c186-fef0012fda79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copied to: /content/drive/MyDrive/ddrm_results/demo_sr4_iter40\n"
          ]
        }
      ]
    }
  ]
}