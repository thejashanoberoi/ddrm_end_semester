{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# DDRM Model Comparison: Three Configurations\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Created:** December 4, 2025  \\n\",\n",
    "    \"**Purpose:** Compare the three model configurations statically analyzed:\\n\",\n",
    "    \"1. **Custom DDPM** (CelebA-HQ)\\n\",\n",
    "    \"2. **OpenAI Guided Diffusion** (ImageNet, unconditional)\\n\",\n",
    "    \"3. **OpenAI Guided Diffusion + Classifier** (ImageNet, class-conditional)\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Analysis Source:** `docs/MODEL_USAGE_ANALYSIS.md`\\n\",\n",
    "    \"\\n\",\n",
    "    \"---\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Overview\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrates that the three models are **MUTUALLY EXCLUSIVE alternatives**, not interdependent:\\n\",\n",
    "    \"\\n\",\n",
    "    \"- **Config 1 (Custom DDPM):** Standalone, no dependencies\\n\",\n",
    "    \"- **Config 2 (OpenAI UNet):** Standalone, no dependencies\\n\",\n",
    "    \"- **Config 3 (OpenAI + Classifier):** Classifier depends on UNet\\n\",\n",
    "    \"\\n\",\n",
    "    \"Each section runs independently and saves results to separate folders for comparison.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Setup: Environment and Dependencies\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Check if running in Colab or local environment\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"IN_COLAB = 'google.colab' in sys.modules\\n\",\n",
    "    \"\\n\",\n",
    "    \"if IN_COLAB:\\n\",\n",
    "    \"    print(\\\"Running in Google Colab\\\")\\n\",\n",
    "    \"    # Clone repository if needed\\n\",\n",
    "    \"    import os\\n\",\n",
    "    \"    if not os.path.exists('ddrm'):\\n\",\n",
    "    \"        !git clone https://github.com/bahjat-kawar/ddrm.git\\n\",\n",
    "    \"    %cd ddrm\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"Running locally - ensure you're in the DDRM directory\\\")\\n\",\n",
    "    \"    import os\\n\",\n",
    "    \"    if not os.path.exists('main.py'):\\n\",\n",
    "    \"        print(\\\"‚ö†Ô∏è Warning: main.py not found. Please cd to DDRM directory.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Install required packages (if not already installed)\\n\",\n",
    "    \"!pip install -q pyyaml tqdm pillow numpy scipy matplotlib\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Import necessary libraries for analysis\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"import time\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"from datetime import datetime\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"from PIL import Image\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"‚úÖ Setup complete\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Download Pre-trained Models and Demo Datasets\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create necessary directories\\n\",\n",
    "    \"!mkdir -p exp/logs/imagenet\\n\",\n",
    "    \"!mkdir -p exp/logs/celeba\\n\",\n",
    "    \"!mkdir -p exp/datasets\\n\",\n",
    "    \"!mkdir -p exp/image_samples\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"üìÅ Directories created\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"%%bash\\n\",\n",
    "    \"# Download OpenAI models for Config 2 & 3 (ImageNet)\\n\",\n",
    "    \"BASE=\\\"https://openaipublic.blob.core.windows.net/diffusion/jul-2021\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"echo \\\"‚è¨ Downloading OpenAI models (~3 GB total)...\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Config 2: Unconditional ImageNet 256x256 (~1.2 GB)\\n\",\n",
    "    \"wget -nc -q --show-progress \\\"$BASE/256x256_diffusion_uncond.pt\\\" -P exp/logs/imagenet\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Config 3: Conditional ImageNet 256x256 + Classifier (~1.7 GB)\\n\",\n",
    "    \"wget -nc -q --show-progress \\\"$BASE/256x256_diffusion.pt\\\" -P exp/logs/imagenet\\n\",\n",
    "    \"wget -nc -q --show-progress \\\"$BASE/256x256_classifier.pt\\\" -P exp/logs/imagenet\\n\",\n",
    "    \"\\n\",\n",
    "    \"echo \\\"‚úÖ OpenAI models downloaded\\\"\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"%%bash\\n\",\n",
    "    \"# Download CelebA-HQ model for Config 1\\n\",\n",
    "    \"CELEBA_URL=\\\"https://image-editing-test-12345.s3-us-west-2.amazonaws.com/checkpoints/celeba_hq.ckpt\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"if [ ! -f exp/logs/celeba/celeba_hq.ckpt ]; then\\n\",\n",
    "    \"    echo \\\"‚è¨ Downloading CelebA-HQ model (~500 MB)...\\\"\\n\",\n",
    "    \"    wget -q --show-progress \\\"$CELEBA_URL\\\" -P exp/logs/celeba/\\n\",\n",
    "    \"    echo \\\"‚úÖ CelebA-HQ model downloaded\\\"\\n\",\n",
    "    \"else\\n\",\n",
    "    \"    echo \\\"‚úÖ CelebA-HQ model already exists\\\"\\n\",\n",
    "    \"fi\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"%%bash\\n\",\n",
    "    \"# Download demo datasets\\n\",\n",
    "    \"echo \\\"‚è¨ Downloading demo datasets...\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"if [ ! -d ddrm-exp-datasets ]; then\\n\",\n",
    "    \"    git clone -q https://github.com/jiamings/ddrm-exp-datasets.git\\n\",\n",
    "    \"    cp -r ddrm-exp-datasets/* exp/datasets/\\n\",\n",
    "    \"    echo \\\"‚úÖ Demo datasets downloaded\\\"\\n\",\n",
    "    \"else\\n\",\n",
    "    \"    echo \\\"‚úÖ Demo datasets already exist\\\"\\n\",\n",
    "    \"fi\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Download ImageNet validation list\\n\",\n",
    "    \"if [ ! -f exp/imagenet_val_1k.txt ]; then\\n\",\n",
    "    \"    wget -q -O exp/imagenet_val_1k.txt \\\\\\n\",\n",
    "    \"        https://raw.githubusercontent.com/XingangPan/deep-generative-prior/master/scripts/imagenet_val_1k.txt\\n\",\n",
    "    \"    echo \\\"‚úÖ ImageNet validation list downloaded\\\"\\n\",\n",
    "    \"else\\n\",\n",
    "    \"    echo \\\"‚úÖ ImageNet validation list already exists\\\"\\n\",\n",
    "    \"fi\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Verify downloads\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"\\n\",\n",
    "    \"models_to_check = [\\n\",\n",
    "    \"    (\\\"Config 1: CelebA-HQ (Custom DDPM)\\\", \\\"exp/logs/celeba/celeba_hq.ckpt\\\"),\\n\",\n",
    "    \"    (\\\"Config 2: ImageNet Uncond (OpenAI)\\\", \\\"exp/logs/imagenet/256x256_diffusion_uncond.pt\\\"),\\n\",\n",
    "    \"    (\\\"Config 3: ImageNet Cond (OpenAI)\\\", \\\"exp/logs/imagenet/256x256_diffusion.pt\\\"),\\n\",\n",
    "    \"    (\\\"Config 3: Classifier\\\", \\\"exp/logs/imagenet/256x256_classifier.pt\\\"),\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nüìä Model Files Status:\\\")\\n\",\n",
    "    \"print(\\\"=\\\" * 80)\\n\",\n",
    "    \"all_exist = True\\n\",\n",
    "    \"for name, path in models_to_check:\\n\",\n",
    "    \"    exists = os.path.exists(path)\\n\",\n",
    "    \"    size = os.path.getsize(path) / (1024**3) if exists else 0  # GB\\n\",\n",
    "    \"    status = \\\"‚úÖ\\\" if exists else \\\"‚ùå\\\"\\n\",\n",
    "    \"    print(f\\\"{status} {name:45s} {size:>6.2f} GB\\\" if exists else f\\\"{status} {name:45s} MISSING\\\")\\n\",\n",
    "    \"    all_exist = all_exist and exists\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"=\\\" * 80)\\n\",\n",
    "    \"if all_exist:\\n\",\n",
    "    \"    print(\\\"‚úÖ All models downloaded successfully!\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"‚ö†Ô∏è Some models are missing. Re-run download cells.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"---\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Configuration 1: Custom DDPM Model (CelebA-HQ)\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Key Characteristics:\\n\",\n",
    "    \"- **Model Type:** Custom DDPM (`type: \\\"simple\\\"`)\\n\",\n",
    "    \"- **Dataset:** CelebA-HQ (face images)\\n\",\n",
    "    \"- **Architecture:** Custom U-Net (128 base channels)\\n\",\n",
    "    \"- **Classifier:** ‚ùå None (`cls_fn = None`)\\n\",\n",
    "    \"- **Independence:** ‚úÖ Runs standalone\\n\",\n",
    "    \"- **Memory:** ~1-2 GB VRAM\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Degradation Task:\\n\",\n",
    "    \"- 4x Super-Resolution with noise (sigma_0 = 0.05)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Configuration 1: Custom DDPM\\n\",\n",
    "    \"config1_params = {\\n\",\n",
    "    \"    \\\"config\\\": \\\"celeba_hq.yml\\\",\\n\",\n",
    "    \"    \\\"doc\\\": \\\"celeba\\\",\\n\",\n",
    "    \"    \\\"timesteps\\\": 20,  # Reduced for faster demo\\n\",\n",
    "    \"    \\\"eta\\\": 0.85,\\n\",\n",
    "    \"    \\\"etaB\\\": 1.0,\\n\",\n",
    "    \"    \\\"deg\\\": \\\"sr4\\\",  # 4x super-resolution\\n\",\n",
    "    \"    \\\"sigma_0\\\": 0.05,\\n\",\n",
    "    \"    \\\"image_folder\\\": \\\"config1_custom_ddpm\\\",\\n\",\n",
    "    \"    \\\"subset_start\\\": 0,\\n\",\n",
    "    \"    \\\"subset_end\\\": 5,  # Process 5 images\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"üîß Configuration 1: Custom DDPM (CelebA-HQ)\\\")\\n\",\n",
    "    \"print(\\\"=\\\" * 60)\\n\",\n",
    "    \"print(f\\\"Config file: {config1_params['config']}\\\")\\n\",\n",
    "    \"print(f\\\"Model type: Custom DDPM (type='simple')\\\")\\n\",\n",
    "    \"print(f\\\"Classifier: None\\\")\\n\",\n",
    "    \"print(f\\\"Task: {config1_params['deg']} (4x super-resolution)\\\")\\n\",\n",
    "    \"print(f\\\"Noise level: {config1_params['sigma_0']}\\\")\\n\",\n",
    "    \"print(f\\\"Timesteps: {config1_params['timesteps']}\\\")\\n\",\n",
    "    \"print(f\\\"Images: {config1_params['subset_end']} samples\\\")\\n\",\n",
    "    \"print(f\\\"Output: exp/image_samples/{config1_params['image_folder']}/\\\")\\n\",\n",
    "    \"print(\\\"=\\\" * 60)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"%%time\\n\",\n",
    "    \"# Run Configuration 1\\n\",\n",
    "    \"print(\\\"\\\\nüöÄ Running Configuration 1...\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"!python main.py --ni \\\\\\n\",\n",
    "    \"    --config {config1_params['config']} \\\\\\n\",\n",
    "    \"    --doc {config1_params['doc']} \\\\\\n\",\n",
    "    \"    --timesteps {config1_params['timesteps']} \\\\\\n\",\n",
    "    \"    --eta {config1_params['eta']} \\\\\\n\",\n",
    "    \"    --etaB {config1_params['etaB']} \\\\\\n\",\n",
    "    \"    --deg {config1_params['deg']} \\\\\\n\",\n",
    "    \"    --sigma_0 {config1_params['sigma_0']} \\\\\\n\",\n",
    "    \"    -i {config1_params['image_folder']} \\\\\\n\",\n",
    "    \"    --subset_start {config1_params['subset_start']} \\\\\\n\",\n",
    "    \"    --subset_end {config1_params['subset_end']}\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n‚úÖ Configuration 1 complete!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"---\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Configuration 2: OpenAI Guided Diffusion (ImageNet, Unconditional)\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Key Characteristics:\\n\",\n",
    "    \"- **Model Type:** OpenAI UNet (`type: \\\"openai\\\"`)\\n\",\n",
    "    \"- **Dataset:** ImageNet\\n\",\n",
    "    \"- **Architecture:** OpenAI U-Net (256 channels, FP16)\\n\",\n",
    "    \"- **Classifier:** ‚ùå None (`class_cond: false`, `cls_fn = None`)\\n\",\n",
    "    \"- **Independence:** ‚úÖ Runs standalone\\n\",\n",
    "    \"- **Memory:** ~2-4 GB VRAM\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Degradation Task:\\n\",\n",
    "    \"- Uniform deblurring (no added noise)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Configuration 2: OpenAI Guided Diffusion (unconditional)\\n\",\n",
    "    \"config2_params = {\\n\",\n",
    "    \"    \\\"config\\\": \\\"imagenet_256.yml\\\",\\n\",\n",
    "    \"    \\\"doc\\\": \\\"imagenet\\\",\\n\",\n",
    "    \"    \\\"timesteps\\\": 20,\\n\",\n",
    "    \"    \\\"eta\\\": 0.85,\\n\",\n",
    "    \"    \\\"etaB\\\": 1.0,\\n\",\n",
    "    \"    \\\"deg\\\": \\\"deblur_uni\\\",  # Uniform deblurring\\n\",\n",
    "    \"    \\\"sigma_0\\\": 0.0,\\n\",\n",
    "    \"    \\\"image_folder\\\": \\\"config2_openai_uncond\\\",\\n\",\n",
    "    \"    \\\"subset_start\\\": 0,\\n\",\n",
    "    \"    \\\"subset_end\\\": 5,\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"üîß Configuration 2: OpenAI Guided Diffusion (Unconditional)\\\")\\n\",\n",
    "    \"print(\\\"=\\\" * 60)\\n\",\n",
    "    \"print(f\\\"Config file: {config2_params['config']}\\\")\\n\",\n",
    "    \"print(f\\\"Model type: OpenAI UNet (type='openai')\\\")\\n\",\n",
    "    \"print(f\\\"Classifier: None (class_cond=false)\\\")\\n\",\n",
    "    \"print(f\\\"Task: {config2_params['deg']} (uniform deblurring)\\\")\\n\",\n",
    "    \"print(f\\\"Noise level: {config2_params['sigma_0']}\\\")\\n\",\n",
    "    \"print(f\\\"Timesteps: {config2_params['timesteps']}\\\")\\n\",\n",
    "    \"print(f\\\"Images: {config2_params['subset_end']} samples\\\")\\n\",\n",
    "    \"print(f\\\"Output: exp/image_samples/{config2_params['image_folder']}/\\\")\\n\",\n",
    "    \"print(\\\"=\\\" * 60)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"%%time\\n\",\n",
    "    \"# Run Configuration 2\\n\",\n",
    "    \"print(\\\"\\\\nüöÄ Running Configuration 2...\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"!python main.py --ni \\\\\\n\",\n",
    "    \"    --config {config2_params['config']} \\\\\\n\",\n",
    "    \"    --doc {config2_params['doc']} \\\\\\n\",\n",
    "    \"    --timesteps {config2_params['timesteps']} \\\\\\n\",\n",
    "    \"    --eta {config2_params['eta']} \\\\\\n\",\n",
    "    \"    --etaB {config2_params['etaB']} \\\\\\n\",\n",
    "    \"    --deg {config2_params['deg']} \\\\\\n\",\n",
    "    \"    --sigma_0 {config2_params['sigma_0']} \\\\\\n\",\n",
    "    \"    -i {config2_params['image_folder']} \\\\\\n\",\n",
    "    \"    --subset_start {config2_params['subset_start']} \\\\\\n\",\n",
    "    \"    --subset_end {config2_params['subset_end']}\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n‚úÖ Configuration 2 complete!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"---\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Configuration 3: OpenAI Guided Diffusion + Classifier (ImageNet, Conditional)\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Key Characteristics:\\n\",\n",
    "    \"- **Model Type:** OpenAI UNet (`type: \\\"openai\\\"`)\\n\",\n",
    "    \"- **Dataset:** ImageNet\\n\",\n",
    "    \"- **Architecture:** OpenAI U-Net (256 channels, FP16)\\n\",\n",
    "    \"- **Classifier:** ‚úÖ **LOADED** (`class_cond: true`, `cls_fn = cond_fn`)\\n\",\n",
    "    \"- **Independence:** ‚ö†Ô∏è Classifier depends on UNet (cannot run alone)\\n\",\n",
    "    \"- **Memory:** ~3-5 GB VRAM\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Degradation Task:\\n\",\n",
    "    \"- 4x Super-Resolution with noise (sigma_0 = 0.05)\\n\",\n",
    "    \"- **With class-conditional guidance**\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Configuration 3: OpenAI + Classifier\\n\",\n",
    "    \"config3_params = {\\n\",\n",
    "    \"    \\\"config\\\": \\\"imagenet_256_cc.yml\\\",\\n\",\n",
    "    \"    \\\"doc\\\": \\\"imagenet\\\",\\n\",\n",
    "    \"    \\\"timesteps\\\": 20,\\n\",\n",
    "    \"    \\\"eta\\\": 0.85,\\n\",\n",
    "    \"    \\\"etaB\\\": 1.0,\\n\",\n",
    "    \"    \\\"deg\\\": \\\"sr4\\\",  # 4x super-resolution\\n\",\n",
    "    \"    \\\"sigma_0\\\": 0.05,\\n\",\n",
    "    \"    \\\"image_folder\\\": \\\"config3_openai_classifier\\\",\\n\",\n",
    "    \"    \\\"subset_start\\\": 0,\\n\",\n",
    "    \"    \\\"subset_end\\\": 5,\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"üîß Configuration 3: OpenAI + Classifier (Conditional)\\\")\\n\",\n",
    "    \"print(\\\"=\\\" * 60)\\n\",\n",
    "    \"print(f\\\"Config file: {config3_params['config']}\\\")\\n\",\n",
    "    \"print(f\\\"Model type: OpenAI UNet (type='openai')\\\")\\n\",\n",
    "    \"print(f\\\"Classifier: ‚úÖ LOADED (class_cond=true)\\\")\\n\",\n",
    "    \"print(f\\\"  ‚îî‚îÄ Provides gradient guidance for class-conditional generation\\\")\\n\",\n",
    "    \"print(f\\\"Task: {config3_params['deg']} (4x super-resolution)\\\")\\n\",\n",
    "    \"print(f\\\"Noise level: {config3_params['sigma_0']}\\\")\\n\",\n",
    "    \"print(f\\\"Timesteps: {config3_params['timesteps']}\\\")\\n\",\n",
    "    \"print(f\\\"Images: {config3_params['subset_end']} samples\\\")\\n\",\n",
    "    \"print(f\\\"Output: exp/image_samples/{config3_params['image_folder']}/\\\")\\n\",\n",
    "    \"print(\\\"=\\\" * 60)\\n\",\n",
    "    \"print(\\\"\\\\n‚ö†Ô∏è Note: Classifier is DEPENDENT on UNet (cannot run alone)\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"%%time\\n\",\n",
    "    \"# Run Configuration 3\\n\",\n",
    "    \"print(\\\"\\\\nüöÄ Running Configuration 3...\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"!python main.py --ni \\\\\\n\",\n",
    "    \"    --config {config3_params['config']} \\\\\\n\",\n",
    "    \"    --doc {config3_params['doc']} \\\\\\n\",\n",
    "    \"    --timesteps {config3_params['timesteps']} \\\\\\n\",\n",
    "    \"    --eta {config3_params['eta']} \\\\\\n\",\n",
    "    \"    --etaB {config3_params['etaB']} \\\\\\n\",\n",
    "    \"    --deg {config3_params['deg']} \\\\\\n\",\n",
    "    \"    --sigma_0 {config3_params['sigma_0']} \\\\\\n\",\n",
    "    \"    -i {config3_params['image_folder']} \\\\\\n\",\n",
    "    \"    --subset_start {config3_params['subset_start']} \\\\\\n\",\n",
    "    \"    --subset_end {config3_params['subset_end']}\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n‚úÖ Configuration 3 complete!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"---\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Results Comparison and Visualization\\n\",\n",
    "    \"\\n\",\n",
    "    \"Now we'll compile and compare the results from all three configurations.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Helper function to load and display images\\n\",\n",
    "    \"def load_image(path):\\n\",\n",
    "    \"    \\\"\\\"\\\"Load image and return as numpy array.\\\"\\\"\\\"\\n\",\n",
    "    \"    if os.path.exists(path):\\n\",\n",
    "    \"        return np.array(Image.open(path))\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        return None\\n\",\n",
    "    \"\\n\",\n",
    "    \"def display_comparison(config_name, folder, img_idx, task_type):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Display original, degraded, and restored images for one configuration.\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        config_name: Name of configuration (e.g., 'Config 1: Custom DDPM')\\n\",\n",
    "    \"        folder: Output folder name\\n\",\n",
    "    \"        img_idx: Image index\\n\",\n",
    "    \"        task_type: Degradation type (e.g., 'Super-Resolution', 'Deblurring')\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    base_path = f\\\"exp/image_samples/{folder}\\\"\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    orig = load_image(f\\\"{base_path}/orig_{img_idx}.png\\\")\\n\",\n",
    "    \"    degraded = load_image(f\\\"{base_path}/y0_{img_idx}.png\\\")\\n\",\n",
    "    \"    restored = load_image(f\\\"{base_path}/{img_idx}_-1.png\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\\n\",\n",
    "    \"    fig.suptitle(f\\\"{config_name} - Image {img_idx} ({task_type})\\\", fontsize=14, fontweight='bold')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if orig is not None:\\n\",\n",
    "    \"        axes[0].imshow(orig)\\n\",\n",
    "    \"        axes[0].set_title(\\\"Original\\\", fontsize=12)\\n\",\n",
    "    \"        axes[0].axis('off')\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        axes[0].text(0.5, 0.5, \\\"Not Found\\\", ha='center', va='center')\\n\",\n",
    "    \"        axes[0].axis('off')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if degraded is not None:\\n\",\n",
    "    \"        axes[1].imshow(degraded)\\n\",\n",
    "    \"        axes[1].set_title(\\\"Degraded\\\", fontsize=12)\\n\",\n",
    "    \"        axes[1].axis('off')\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        axes[1].text(0.5, 0.5, \\\"Not Found\\\", ha='center', va='center')\\n\",\n",
    "    \"        axes[1].axis('off')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if restored is not None:\\n\",\n",
    "    \"        axes[2].imshow(restored)\\n\",\n",
    "    \"        axes[2].set_title(\\\"Restored\\\", fontsize=12)\\n\",\n",
    "    \"        axes[2].axis('off')\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        axes[2].text(0.5, 0.5, \\\"Not Found\\\", ha='center', va='center')\\n\",\n",
    "    \"        axes[2].axis('off')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"‚úÖ Visualization functions loaded\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Configuration 1 Results: Custom DDPM (CelebA-HQ)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Display results from Configuration 1\\n\",\n",
    "    \"print(\\\"üìä Configuration 1: Custom DDPM (CelebA-HQ)\\\")\\n\",\n",
    "    \"print(\\\"Task: 4x Super-Resolution with noise\\\")\\n\",\n",
    "    \"print(\\\"Model: Custom DDPM (standalone, no classifier)\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"for i in range(min(3, config1_params['subset_end'])):  # Show first 3 images\\n\",\n",
    "    \"    display_comparison(\\n\",\n",
    "    \"        \\\"Config 1: Custom DDPM\\\",\\n\",\n",
    "    \"        config1_params['image_folder'],\\n\",\n",
    "    \"        i,\\n\",\n",
    "    \"        \\\"4x Super-Resolution\\\"\\n\",\n",
    "    \"    )\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Configuration 2 Results: OpenAI Guided Diffusion (Unconditional)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Display results from Configuration 2\\n\",\n",
    "    \"print(\\\"üìä Configuration 2: OpenAI Guided Diffusion (Unconditional)\\\")\\n\",\n",
    "    \"print(\\\"Task: Uniform Deblurring\\\")\\n\",\n",
    "    \"print(\\\"Model: OpenAI UNet (standalone, no classifier)\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"for i in range(min(3, config2_params['subset_end'])):\\n\",\n",
    "    \"    display_comparison(\\n\",\n",
    "    \"        \\\"Config 2: OpenAI UNet\\\",\\n\",\n",
    "    \"        config2_params['image_folder'],\\n\",\n",
    "    \"        i,\\n\",\n",
    "    \"        \\\"Uniform Deblurring\\\"\\n\",\n",
    "    \"    )\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Configuration 3 Results: OpenAI + Classifier (Conditional)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Display results from Configuration 3\\n\",\n",
    "    \"print(\\\"üìä Configuration 3: OpenAI + Classifier (Conditional)\\\")\\n\",\n",
    "    \"print(\\\"Task: 4x Super-Resolution with noise\\\")\\n\",\n",
    "    \"print(\\\"Model: OpenAI UNet + Classifier (classifier depends on UNet)\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"for i in range(min(3, config3_params['subset_end'])):\\n\",\n",
    "    \"    display_comparison(\\n\",\n",
    "    \"        \\\"Config 3: OpenAI + Classifier\\\",\\n\",\n",
    "    \"        config3_params['image_folder'],\\n\",\n",
    "    \"        i,\\n\",\n",
    "    \"        \\\"4x SR with Class Guidance\\\"\\n\",\n",
    "    \"    )\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"---\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Side-by-Side Comparison: All Three Configurations\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def compare_all_configs(img_idx=0):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Compare restored images from all three configurations side-by-side.\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    Note: Config 1 uses CelebA (faces), Configs 2 & 3 use ImageNet (general),\\n\",\n",
    "    \"    so direct pixel comparison may not be meaningful. This demonstrates that\\n\",\n",
    "    \"    each config runs independently on different data.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\\n\",\n",
    "    \"    fig.suptitle(f\\\"Restored Images Comparison (Image {img_idx})\\\", fontsize=16, fontweight='bold')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    configs = [\\n\",\n",
    "    \"        (\\\"Config 1\\\\nCustom DDPM\\\\n(CelebA, 4x SR)\\\", config1_params['image_folder']),\\n\",\n",
    "    \"        (\\\"Config 2\\\\nOpenAI UNet\\\\n(ImageNet, Deblur)\\\", config2_params['image_folder']),\\n\",\n",
    "    \"        (\\\"Config 3\\\\nOpenAI + Classifier\\\\n(ImageNet, 4x SR)\\\", config3_params['image_folder']),\\n\",\n",
    "    \"    ]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for idx, (title, folder) in enumerate(configs):\\n\",\n",
    "    \"        restored = load_image(f\\\"exp/image_samples/{folder}/{img_idx}_-1.png\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if restored is not None:\\n\",\n",
    "    \"            axes[idx].imshow(restored)\\n\",\n",
    "    \"            axes[idx].set_title(title, fontsize=11, fontweight='bold')\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            axes[idx].text(0.5, 0.5, \\\"Not Found\\\", ha='center', va='center')\\n\",\n",
    "    \"            axes[idx].set_title(title, fontsize=11)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        axes[idx].axis('off')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Show comparison for first image\\n\",\n",
    "    \"print(\\\"üìä Side-by-Side Comparison of All Three Configurations\\\\n\\\")\\n\",\n",
    "    \"compare_all_configs(img_idx=0)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"---\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Performance and Memory Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze output directories and file counts\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"\\n\",\n",
    "    \"def analyze_output(config_name, folder, expected_count):\\n\",\n",
    "    \"    \\\"\\\"\\\"Analyze output files from a configuration.\\\"\\\"\\\"\\n\",\n",
    "    \"    base_path = f\\\"exp/image_samples/{folder}\\\"\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if not os.path.exists(base_path):\\n\",\n",
    "    \"        print(f\\\"‚ùå {config_name}: Output folder not found\\\")\\n\",\n",
    "    \"        return\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    files = os.listdir(base_path)\\n\",\n",
    "    \"    orig_files = [f for f in files if f.startswith('orig_')]\\n\",\n",
    "    \"    degraded_files = [f for f in files if f.startswith('y0_')]\\n\",\n",
    "    \"    restored_files = [f for f in files if '_-1.png' in f]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    total_size = sum(os.path.getsize(os.path.join(base_path, f)) for f in files) / (1024**2)  # MB\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\n{config_name}\\\")\\n\",\n",
    "    \"    print(\\\"‚îÄ\\\" * 60)\\n\",\n",
    "    \"    print(f\\\"  Output folder: {folder}\\\")\\n\",\n",
    "    \"    print(f\\\"  Original images: {len(orig_files)} / {expected_count}\\\")\\n\",\n",
    "    \"    print(f\\\"  Degraded images: {len(degraded_files)} / {expected_count}\\\")\\n\",\n",
    "    \"    print(f\\\"  Restored images: {len(restored_files)} / {expected_count}\\\")\\n\",\n",
    "    \"    print(f\\\"  Total output size: {total_size:.2f} MB\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    status = \\\"‚úÖ\\\" if len(restored_files) == expected_count else \\\"‚ö†Ô∏è\\\"\\n\",\n",
    "    \"    print(f\\\"  Status: {status}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"üìä Output Analysis\\\")\\n\",\n",
    "    \"print(\\\"=\\\" * 60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"analyze_output(\\\"Config 1: Custom DDPM\\\", config1_params['image_folder'], config1_params['subset_end'])\\n\",\n",
    "    \"analyze_output(\\\"Config 2: OpenAI UNet\\\", config2_params['image_folder'], config2_params['subset_end'])\\n\",\n",
    "    \"analyze_output(\\\"Config 3: OpenAI + Classifier\\\", config3_params['image_folder'], config3_params['subset_end'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\" * 60)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"---\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Model Dependency Summary\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Key Findings (from static analysis):\\n\",\n",
    "    \"\\n\",\n",
    "    \"| Configuration | Diffusion Model | Classifier | Can Run Alone? | Memory |\\n\",\n",
    "    \"|---------------|-----------------|------------|----------------|--------|\\n\",\n",
    "    \"| **Config 1** | Custom DDPM | ‚ùå None | ‚úÖ Yes | ~1-2 GB |\\n\",\n",
    "    \"| **Config 2** | OpenAI UNet | ‚ùå None | ‚úÖ Yes | ~2-4 GB |\\n\",\n",
    "    \"| **Config 3** | OpenAI UNet | ‚úÖ Loaded | ‚ö†Ô∏è Classifier needs UNet | ~3-5 GB |\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Architecture Pattern:\\n\",\n",
    "    \"\\n\",\n",
    "    \"```\\n\",\n",
    "    \"Config 1: [Custom DDPM] ‚îÄ‚îÄ‚Üí Restoration\\n\",\n",
    "    \"           (standalone)\\n\",\n",
    "    \"\\n\",\n",
    "    \"Config 2: [OpenAI UNet] ‚îÄ‚îÄ‚Üí Restoration\\n\",\n",
    "    \"           (standalone)\\n\",\n",
    "    \"\\n\",\n",
    "    \"Config 3: [OpenAI UNet] ‚îÄ‚îÄ‚îê\\n\",\n",
    "    \"                          ‚îú‚îÄ‚îÄ‚Üí Restoration (with guidance)\\n\",\n",
    "    \"          [Classifier] ‚îÄ‚îÄ‚îÄ‚îò\\n\",\n",
    "    \"           (depends on UNet)\\n\",\n",
    "    \"```\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Impossible Combinations:\\n\",\n",
    "    \"- ‚ùå Custom DDPM + OpenAI UNet (mutually exclusive)\\n\",\n",
    "    \"- ‚ùå Custom DDPM + Classifier (classifier only works with OpenAI)\\n\",\n",
    "    \"- ‚ùå Classifier alone (needs diffusion model)\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Code Evidence:\\n\",\n",
    "    \"- **File:** `runners/diffusion.py:93-165`\\n\",\n",
    "    \"- **Logic:** `if-elif` structure ensures only ONE diffusion model loads\\n\",\n",
    "    \"- **Classifier:** Only loads when `type='openai'` AND `class_cond=true`\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"---\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Generate Comparison Report\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Generate JSON report\\n\",\n",
    "    \"report = {\\n\",\n",
    "    \"    \\\"experiment_date\\\": datetime.now().isoformat(),\\n\",\n",
    "    \"    \\\"configurations\\\": [\\n\",\n",
    "    \"        {\\n\",\n",
    "    \"            \\\"id\\\": 1,\\n\",\n",
    "    \"            \\\"name\\\": \\\"Custom DDPM (CelebA-HQ)\\\",\\n\",\n",
    "    \"            \\\"model_type\\\": \\\"simple\\\",\\n\",\n",
    "    \"            \\\"diffusion_model\\\": \\\"Custom DDPM\\\",\\n\",\n",
    "    \"            \\\"classifier\\\": None,\\n\",\n",
    "    \"            \\\"independent\\\": True,\\n\",\n",
    "    \"            \\\"dataset\\\": \\\"CelebA-HQ\\\",\\n\",\n",
    "    \"            \\\"task\\\": \\\"4x Super-Resolution\\\",\\n\",\n",
    "    \"            \\\"config_file\\\": config1_params['config'],\\n\",\n",
    "    \"            \\\"output_folder\\\": config1_params['image_folder'],\\n\",\n",
    "    \"            \\\"params\\\": config1_params,\\n\",\n",
    "    \"        },\\n\",\n",
    "    \"        {\\n\",\n",
    "    \"            \\\"id\\\": 2,\\n\",\n",
    "    \"            \\\"name\\\": \\\"OpenAI Guided Diffusion (Unconditional)\\\",\\n\",\n",
    "    \"            \\\"model_type\\\": \\\"openai\\\",\\n\",\n",
    "    \"            \\\"diffusion_model\\\": \\\"OpenAI UNet\\\",\\n\",\n",
    "    \"            \\\"classifier\\\": None,\\n\",\n",
    "    \"            \\\"independent\\\": True,\\n\",\n",
    "    \"            \\\"dataset\\\": \\\"ImageNet\\\",\\n\",\n",
    "    \"            \\\"task\\\": \\\"Uniform Deblurring\\\",\\n\",\n",
    "    \"            \\\"config_file\\\": config2_params['config'],\\n\",\n",
    "    \"            \\\"output_folder\\\": config2_params['image_folder'],\\n\",\n",
    "    \"            \\\"params\\\": config2_params,\\n\",\n",
    "    \"        },\\n\",\n",
    "    \"        {\\n\",\n",
    "    \"            \\\"id\\\": 3,\\n\",\n",
    "    \"            \\\"name\\\": \\\"OpenAI + Classifier (Conditional)\\\",\\n\",\n",
    "    \"            \\\"model_type\\\": \\\"openai\\\",\\n\",\n",
    "    \"            \\\"diffusion_model\\\": \\\"OpenAI UNet\\\",\\n\",\n",
    "    \"            \\\"classifier\\\": \\\"EncoderUNetModel\\\",\\n\",\n",
    "    \"            \\\"independent\\\": False,\\n\",\n",
    "    \"            \\\"dependency\\\": \\\"Classifier depends on UNet\\\",\\n\",\n",
    "    \"            \\\"dataset\\\": \\\"ImageNet\\\",\\n\",\n",
    "    \"            \\\"task\\\": \\\"4x Super-Resolution (class-guided)\\\",\\n\",\n",
    "    \"            \\\"config_file\\\": config3_params['config'],\\n\",\n",
    "    \"            \\\"output_folder\\\": config3_params['image_folder'],\\n\",\n",
    "    \"            \\\"params\\\": config3_params,\\n\",\n",
    "    \"        },\\n\",\n",
    "    \"    ],\\n\",\n",
    "    \"    \\\"key_findings\\\": {\\n\",\n",
    "    \"        \\\"models_are_alternatives\\\": True,\\n\",\n",
    "    \"        \\\"mutually_exclusive\\\": \\\"Custom DDPM and OpenAI UNet cannot run together\\\",\\n\",\n",
    "    \"        \\\"classifier_dependency\\\": \\\"Classifier requires OpenAI UNet, cannot run alone\\\",\\n\",\n",
    "    \"        \\\"architecture_pattern\\\": \\\"Strategy (choose diffusion model) + Decorator (optional classifier)\\\",\\n\",\n",
    "    \"    },\\n\",\n",
    "    \"    \\\"reference\\\": \\\"docs/MODEL_USAGE_ANALYSIS.md\\\",\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save report\\n\",\n",
    "    \"report_path = \\\"exp/image_samples/comparison_report.json\\\"\\n\",\n",
    "    \"with open(report_path, 'w') as f:\\n\",\n",
    "    \"    json.dump(report, f, indent=2)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"‚úÖ Comparison report saved to: {report_path}\\\")\\n\",\n",
    "    \"print(\\\"\\\\nüìÑ Report Summary:\\\")\\n\",\n",
    "    \"print(json.dumps(report['key_findings'], indent=2))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"---\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Conclusion\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Demonstrated Facts:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. ‚úÖ **Three configurations ran successfully** - each produced restored images\\n\",\n",
    "    \"2. ‚úÖ **Configurations 1 & 2 are independent** - different models, no overlap\\n\",\n",
    "    \"3. ‚úÖ **Configuration 3 shows dependency** - classifier loaded alongside UNet\\n\",\n",
    "    \"4. ‚úÖ **Models are alternatives** - only ONE diffusion model per run\\n\",\n",
    "    \"5. ‚úÖ **Output folders are separate** - no interference between configs\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Static Analysis Validated:\\n\",\n",
    "    \"\\n\",\n",
    "    \"The runtime behavior confirms the static analysis findings from `docs/MODEL_USAGE_ANALYSIS.md`:\\n\",\n",
    "    \"- Models are **mutually exclusive alternatives**\\n\",\n",
    "    \"- Classifier is an **optional add-on** (only with OpenAI)\\n\",\n",
    "    \"- Each configuration can run **independently** (except classifier needs UNet)\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Architecture Pattern:\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Strategy Pattern:** Choose ONE diffusion model based on dataset\\n\",\n",
    "    \"- Custom DDPM for faces (CelebA)\\n\",\n",
    "    \"- OpenAI UNet for general images (ImageNet)\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Decorator Pattern:** Optionally add classifier guidance\\n\",\n",
    "    \"- Base: OpenAI UNet\\n\",\n",
    "    \"- Decorator: Classifier (provides gradient guidance)\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Next Steps:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. Compare PSNR metrics across configurations (if computed)\\n\",\n",
    "    \"2. Analyze perceptual quality differences\\n\",\n",
    "    \"3. Test with different degradation types\\n\",\n",
    "    \"4. Experiment with different hyperparameters\\n\",\n",
    "    \"\\n\",\n",
    "    \"---\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Notebook created:** December 4, 2025  \\n\",\n",
    "    \"**Based on:** Static analysis in `docs/MODEL_USAGE_ANALYSIS.md`  \\n\",\n",
    "    \"**Repository:** DDRM - Denoising Diffusion Restoration Models\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.7\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}\n",
    "\n"
   ],
   "id": "d821a54ade56ce6"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
