# Architectural Differences - Visual Summary

```
╔═══════════════════════════════════════════════════════════════════╗
║         THREE MODEL ARCHITECTURES - VISUAL COMPARISON             ║
╚═══════════════════════════════════════════════════════════════════╝

┌───────────────────────────────────────────────────────────────────┐
│                    CONFIG 1: CUSTOM DDPM                          │
│                  (Simple, Domain-Specific)                        │
└───────────────────────────────────────────────────────────────────┘

         Input (3×256×256)
              │
         ┌────▼────┐
         │ Conv_in │  3 → 128 channels
         └────┬────┘
              │
    ┌─────────▼─────────┐
    │   ENCODER (Down)  │
    │                   │
    │ Level 0: 128ch    │ 256×256  ─┐
    │ Level 1: 128ch    │ 128×128  ─┤
    │ Level 2: 256ch    │  64×64   ─┤  ResBlocks
    │ Level 3: 256ch    │  32×32   ─┤  (2 per level)
    │ Level 4: 512ch ⚡ │  16×16   ─┤  ⚡ = Attention
    │ Level 5: 512ch    │   8×8    ─┘
    └─────────┬─────────┘
              │
    ┌─────────▼─────────┐
    │   MIDDLE BLOCK    │
    │ ResBlock → Attn ⚡│  8×8
    │    → ResBlock     │
    └─────────┬─────────┘
              │
    ┌─────────▼─────────┐
    │   DECODER (Up)    │
    │                   │
    │ Level 5: 512ch    │   8×8    ─┐
    │ Level 4: 512ch ⚡ │  16×16   ─┤
    │ Level 3: 256ch    │  32×32   ─┤  ResBlocks
    │ Level 2: 256ch    │  64×64   ─┤  (3 per level)
    │ Level 1: 128ch    │ 128×128  ─┤
    │ Level 0: 128ch    │ 256×256  ─┘
    └─────────┬─────────┘
              │
         ┌────▼────┐
         │Conv_out │  128 → 3 channels
         └────┬────┘
              │
         Output (3×256×256)

STATS:
• Base channels: 128
• Max channels: 512
• Attention: 1-head @ 1 level (16×16)
• Parameters: ~60M
• Time embedding: 2-layer MLP
• FP16: ❌ No


┌───────────────────────────────────────────────────────────────────┐
│              CONFIG 2: OPENAI UNET (Unconditional)                │
│                  (Large-Scale, General-Purpose)                   │
└───────────────────────────────────────────────────────────────────┘

         Input (3×256×256)
              │
         ┌────▼────┐
         │ Conv_in │  3 → 256 channels (2× Custom DDPM)
         └────┬────┘
              │
    ┌─────────▼─────────┐
    │   ENCODER (Down)  │
    │                   │
    │ Level 0:  256ch   │ 256×256  ─┐
    │ Level 1:  256ch   │ 128×128  ─┤
    │ Level 2:  512ch ⚡│  64×64   ─┤  ResBlocks
    │ Level 3:  512ch ⚡│  32×32   ─┤  (2 per level)
    │ Level 4: 1024ch ⚡│  16×16   ─┤  ⚡ = 4-head Attn
    │ Level 5: 1024ch ⚡│   8×8    ─┘  (3 levels!)
    └─────────┬─────────┘
              │
    ┌─────────▼─────────┐
    │   MIDDLE BLOCK    │
    │ ResBlock → Attn ⚡│  8×8  (4 heads)
    │    → ResBlock     │
    └─────────┬─────────┘
              │
    ┌─────────▼─────────┐
    │   DECODER (Up)    │
    │  + Skip Connect   │◄─── Skip connections from encoder
    │                   │
    │ Level 5: 1024ch ⚡│   8×8    ─┐
    │ Level 4: 1024ch ⚡│  16×16   ─┤
    │ Level 3:  512ch ⚡│  32×32   ─┤  ResBlocks
    │ Level 2:  512ch ⚡│  64×64   ─┤  (3 per level)
    │ Level 1:  256ch   │ 128×128  ─┤  ⚡ = 4-head Attn
    │ Level 0:  256ch   │ 256×256  ─┘
    └─────────┬─────────┘
              │
    ┌─────────▼─────────┐
    │  GroupNorm+SiLU   │
    │     Conv_out      │  1024 → 3 channels
    └─────────┬─────────┘
              │
         Output (3×256×256)

STATS:
• Base channels: 256 (2× larger)
• Max channels: 1024 (2× larger)
• Attention: 4-heads @ 3 levels (64,32,16)
• Parameters: ~280M (4.7× larger!)
• Time embedding: 3-layer + SiLU + FiLM
• FP16: ✅ Yes (2× faster)


┌───────────────────────────────────────────────────────────────────┐
│         CONFIG 3: OPENAI UNET + CLASSIFIER (Conditional)          │
│              (Controllable, Class-Guided Generation)              │
└───────────────────────────────────────────────────────────────────┘

    ┌─────────────────────────────────────────────────┐
    │            DIFFUSION MODEL (UNet)               │
    │         [IDENTICAL TO CONFIG 2]                 │
    │                                                 │
    │  Input (3×256×256) + timestep t                │
    │         │                                       │
    │    [Same architecture as Config 2]             │
    │         │                                       │
    │  Output: noise prediction e_t                  │
    └─────────────────┬───────────────────────────────┘
                      │
                      │
          ┌───────────┴───────────┐
          │                       │
          ▼                       ▼
    ┌─────────────┐         ┌─────────────────┐
    │   e_t       │         │   CLASSIFIER    │
    │  (noise)    │         │  EncoderUNet    │
    └──────┬──────┘         └────────┬────────┘
           │                         │
           │                    Input: x_t + t
           │                         │
           │                    ┌────▼────┐
           │                    │ Encoder │
           │                    │  Only   │
           │                    └────┬────┘
           │                         │
           │                    ┌────▼────┐
           │                    │ Pooling │
           │                    └────┬────┘
           │                         │
           │                    ┌────▼────┐
           │                    │ Linear  │
           │                    │ 1000cls │
           │                    └────┬────┘
           │                         │
           │                     logits p(y|x_t)
           │                         │
           │                    ┌────▼─────┐
           │                    │ Compute  │
           │                    │ Gradient │
           │                    │∇ log p(y)│
           │                    └────┬─────┘
           │                         │
           │                      gradient
           │                         │
           └────────►◄───────────────┘
                    │
              ┌─────▼─────┐
              │  Combine  │
              │e_t_guided │ = e_t - √(1-ᾱ_t) × scale × gradient
              └─────┬─────┘
                    │
              Use for next step


STATS:
• Diffusion: Same as Config 2 (280M)
• Classifier: ~50-100M additional
• Total: ~350M parameters
• Attention: Same (4-heads @ 3 levels)
• Time embedding: Same (FiLM)
• FP16: ✅ Yes (both models)
• Extra: Gradient computation overhead


╔═══════════════════════════════════════════════════════════════════╗
║                    SIDE-BY-SIDE COMPARISON                        ║
╚═══════════════════════════════════════════════════════════════════╝

┌─────────────┬──────────────┬──────────────┬────────────────────┐
│  Feature    │ Custom DDPM  │ OpenAI UNet  │ OpenAI+Classifier  │
├─────────────┼──────────────┼──────────────┼────────────────────┤
│ Base Ch     │     128      │     256      │       256          │
│ Max Ch      │     512      │    1024      │      1024          │
│ Parameters  │    ~60M      │    ~280M     │      ~350M         │
│             │              │              │                    │
│ Attention:  │              │              │                    │
│  - Heads    │      1       │      4       │        4           │
│  - Levels   │      1       │      3       │        3           │
│  - Where    │    [16]      │  [32,16,8]   │    [32,16,8]       │
│             │              │              │                    │
│ Time Embed  │  2-layer MLP │ 3-layer+SiLU │   3-layer+SiLU     │
│ Conditioning│   Additive   │ FiLM(scale+  │   FiLM(scale+      │
│             │              │     shift)   ��      shift)        │
│             │              │              │                    │
│ FP16        │      ❌      │      ✅      │        ✅          │
│ Checkpoints │      ❌      │      ✅      │        ✅          │
│ Class Cond  │      ❌      │      ❌      │        ✅          │
│             │              │              │                    │
│ Memory      │    ~1 GB     │   ~1.5 GB    │       ~2 GB        │
│ Speed       │    1.0x      │    0.67x     │       0.55x        │
│             │              │              │                    │
│ Best For    │ Faces/Scenes │   General    │    Controlled      │
│             │   Limited    │   ImageNet   │   Class-specific   │
│             │   Compute    │  Production  │     Research       │
└─────────────┴──────────────┴──────────────┴────────────────────┘


╔═══════════════════════════════════════════════════════════════════╗
║              KEY ARCHITECTURAL INNOVATIONS                        ║
╚═══════════════════════════════════════════════════════════════════╝

Custom DDPM → OpenAI UNet:
───────────────────────────────────────────────────────────────────

1. CAPACITY INCREASE (4.7×)
   128 base ch ──────────────────► 256 base ch
   512 max ch  ──────────────────► 1024 max ch
   ~60M params ──────────────────► ~280M params

2. MULTI-HEAD ATTENTION
   1 head @ 16×16 ───────────────► 4 heads @ [32,16,8]

   Single-head:                   Multi-head (4):
   ┌─────────┐                    ┌──┬──┬──┬──┐
   │ Q·K^T   │                    │H1│H2│H3│H4│
   │ Softmax │                    └──┴──┴──┴──┘
   │   V     │                    Concat → Project
   └─────────┘

3. FiLM CONDITIONING (Feature-wise Linear Modulation)
   Additive:                      FiLM:
   h + time_emb ─────────────────► h × (1+scale) + shift

   Less expressive ──────────────► More expressive
   Slower convergence ────────────► Faster convergence

4. FP16 PRECISION
   FP32 only ─────────────────────► FP16/FP32 mixed
   ~100% memory ──────────────────► ~50% memory
   1.0× speed ────────────────────► 2× speed

5. GRADIENT CHECKPOINTING
   Store all activations ─────────► Recompute on backward
   High memory ───────────────────► Lower memory
   No time overhead ──────────────► +15% time, -60% memory


OpenAI UNet → OpenAI UNet + Classifier:
───────────────────────────────────────────────────────────────────

6. CLASSIFIER GUIDANCE
   Unconditional: ────────────────► Class-conditional:

   e_t = UNet(x_t, t)              e_t = UNet(x_t, t)
                                   grad = ∇ log p(y|x_t)
                                   e_t ← e_t - λ·√(1-ᾱ_t)·grad

   No control ────────────────────► Control via class label
   Faster ────────────────────────► +20-30% slower
   One model ─────────────────────► Two models (UNet + Classifier)


╔═══════════════════════════════════════════════════════════════════╗
║                     DESIGN PHILOSOPHY                             ║
╚═══════════════════════════════════════════════════════════════════╝

Custom DDPM (Config 1):
─��─────────────────────
Philosophy: Simplicity & Domain-Specificity

  ┌─────────────────────────────────────┐
  │  "Keep it simple, specialized"      │
  │                                     │
  │  ✓ Minimal architecture             │
  │  ✓ Proven DDPM design              │
  │  ✓ Fast iteration                   │
  │  ✓ Easy to understand               │
  │  ✓ Low compute requirements         │
  │                                     │
  │  Best for: Academic research,       │
  │            Face/scene generation    │
  └─────────────────────────────────────┘


OpenAI UNet (Config 2):
───────────────────────
Philosophy: Scale & Generalization

  ┌─────────────────────────────────────┐
  │  "Scale up, generalize better"      │
  │                                     │
  │  ✓ Large capacity for diversity     │
  │  ✓ SOTA techniques (FiLM, multi-h)  │
  │  ✓ Production features (FP16)       │
  │  ✓ Extensive testing                │
  │  ✓ ImageNet-scale ready             │
  │                                     │
  │  Best for: Production deployment,   │
  │            General-purpose gen      │
  └─────────────────────────────────────┘


OpenAI + Classifier (Config 3):
────────────────────────────────
Philosophy: Controllable via Guidance

  ┌─────────────────────────────────────┐
  │  "Separate generation & guidance"   │
  │                                     │
  │  ✓ Modular (swap classifiers)       │
  │  ✓ No retraining diffusion model    │
  │  ✓ Fine-grained control             │
  │  ✓ Trade compute for quality        │
  │  ✓ Research-friendly                │
  │                                     │
  │  Best for: Controlled generation,   │
  │            Class-specific quality   │
  └─────────────────────────────────────┘


╔═══════════════════════════════════════════════════════════════════╗
║                    PERFORMANCE COMPARISON                         ║
╚═══════════════════════════════════════════════════════════════════╝

Inference Time (256×256, 20 timesteps):
────────────────────────────────────────────────────────────────────

Custom DDPM:   ████████████████████ 100% (baseline)
OpenAI UNet:   ██████████████████████████████ 150% (+50% slower)
+ Classifier:  ████████████████████████████████████ 180% (+80% slower)


Memory Usage (single 256×256 image):
────────────────────────────────────────────────────────────────────

Custom DDPM:   ████████████ ~1.0 GB
OpenAI UNet:   ██████████████████ ~1.5 GB
+ Classifier:  ████████████████████████ ~2.0 GB


Parameter Count:
────────────────────────────────────────────────────────────────────

Custom DDPM:   ████ 60M
OpenAI UNet:   ███████████████████ 280M (4.7× larger)
+ Classifier:  ████████████████████████ 350M (5.8× larger)


Quality on ImageNet (subjective, FID score proxy):
────────────────────────────────────────────────────────────────────

Custom DDPM:   N/A (not designed for ImageNet)
OpenAI UNet:   ███████████████████ Good
+ Classifier:  ████████████████████████ Better (class-conditional boost)


╔═══════════════════════════════════════════════════════════════════╗
║                         SUMMARY                                   ║
╚═══════════════════════════════════════════════════════════════════╝

Three Architectures, Three Purposes:
═════════════════════════════════════

   Config 1              Config 2              Config 3
  (Custom DDPM)        (OpenAI UNet)      (OpenAI+Classifier)
       │                    │                     │
       ▼                    ▼                     ▼
   Lightweight          Heavyweight          Heavyweight+
   Domain-specific      General-purpose      Controllable
   Educational          Production           Research
       │                    │                     │
       │                    │                     │
   60M params           280M params          350M params
   1 attention          3 attentions         3 attentions
   Simple time          FiLM time            FiLM time
   No FP16              FP16 ✓               FP16 ✓
   No class cond        No class cond        Class cond ✓
       │                    │                     │
       └────────────────────┴─────────────────────┘
                           │
                  All share DDPM core:
                           │
              ┌────────────┴────────────┐
              │                         │
          U-Net structure      Time-conditional
          Encoder-decoder       Noise prediction
          Skip connections      DDRM compatible
              │                         │
              └─────────────────────────┘


Key Insight:
═════════════

The three configurations demonstrate an EVOLUTION of diffusion models:

  SIMPLICITY ──────────► SCALE ──────────► CONTROL
  (Custom DDPM)      (OpenAI UNet)    (+ Classifier)

  Domain-specific → General-purpose → Task-specific
  Low compute     → High compute    → Very high compute
  Good quality    → Better quality  → Best quality (targeted)


Choose based on:
═════════════════

┌─────────────────────────────────────────────────────────────┐
│ If you have...          │ Use...                            │
├─────────────────────────┼───────────────────────────────────┤
│ Limited GPU memory      │ Config 1 (Custom DDPM)            │
│ Face/scene dataset      │ Config 1 (Custom DDPM)            │
│ Need understanding      │ Config 1 (Custom DDPM)            │
├─────────────────────────┼───────────────────────────────────┤
│ ImageNet or diverse     │ Config 2 (OpenAI UNet)            │
│ Production deployment   │ Config 2 (OpenAI UNet)            │
│ Need best performance   │ Config 2 (OpenAI UNet)            │
├─────────────────────────┼───────────────────────────────────┤
│ Need class control      │ Config 3 (OpenAI + Classifier)    │
│ Quality > speed         │ Config 3 (OpenAI + Classifier)    │
│ Research on guidance    │ Config 3 (OpenAI + Classifier)    │
└─────────────────────────┴───────────────────────────────────┘
```

**Analysis method:** Static code reading (no execution)
**Created:** December 4, 2025

